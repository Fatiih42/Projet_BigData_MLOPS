{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f824f74f-220e-456c-bfd3-ae045146f5c7",
   "metadata": {},
   "source": [
    "### sujet : Statistiques et trends prédictives sur les langages utilisés ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15c115db-b6cf-4c71-b900-ca05a0fd30d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -yspark (d:\\miniconda3\\envs\\aag-talp\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yspark (d:\\miniconda3\\envs\\aag-talp\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yspark (d:\\miniconda3\\envs\\aag-talp\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd124217-5b97-46df-b800-8a13fa7ac688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données enrichies récupérées : 1000 dépôts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>stars</th>\n",
       "      <th>forks</th>\n",
       "      <th>watchers</th>\n",
       "      <th>open_issues</th>\n",
       "      <th>primary_language</th>\n",
       "      <th>languages</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>freeCodeCamp</td>\n",
       "      <td>411063</td>\n",
       "      <td>39150</td>\n",
       "      <td>411063</td>\n",
       "      <td>253</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>[TypeScript, JavaScript, CSS, Dockerfile, EJS,...</td>\n",
       "      <td>2014-12-24T17:49:19Z</td>\n",
       "      <td>2025-03-09T22:38:20Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>free-programming-books</td>\n",
       "      <td>352089</td>\n",
       "      <td>62944</td>\n",
       "      <td>352089</td>\n",
       "      <td>87</td>\n",
       "      <td>HTML</td>\n",
       "      <td>[HTML]</td>\n",
       "      <td>2013-10-11T06:50:37Z</td>\n",
       "      <td>2025-03-09T22:44:06Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>build-your-own-x</td>\n",
       "      <td>351322</td>\n",
       "      <td>32580</td>\n",
       "      <td>351322</td>\n",
       "      <td>355</td>\n",
       "      <td>Markdown</td>\n",
       "      <td>[Markdown]</td>\n",
       "      <td>2018-05-09T12:03:18Z</td>\n",
       "      <td>2025-03-09T22:51:09Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>awesome</td>\n",
       "      <td>350600</td>\n",
       "      <td>28668</td>\n",
       "      <td>350600</td>\n",
       "      <td>51</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2014-07-11T13:42:37Z</td>\n",
       "      <td>2025-03-09T22:46:56Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>public-apis</td>\n",
       "      <td>329757</td>\n",
       "      <td>34956</td>\n",
       "      <td>329757</td>\n",
       "      <td>470</td>\n",
       "      <td>Python</td>\n",
       "      <td>[Python, Shell]</td>\n",
       "      <td>2016-03-20T23:49:42Z</td>\n",
       "      <td>2025-03-09T22:50:53Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>headscale</td>\n",
       "      <td>25915</td>\n",
       "      <td>1402</td>\n",
       "      <td>25915</td>\n",
       "      <td>117</td>\n",
       "      <td>Go</td>\n",
       "      <td>[Go, HTML, Nix, Shell, Makefile]</td>\n",
       "      <td>2020-06-21T09:21:05Z</td>\n",
       "      <td>2025-03-09T22:36:14Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>fyne</td>\n",
       "      <td>25901</td>\n",
       "      <td>1422</td>\n",
       "      <td>25901</td>\n",
       "      <td>699</td>\n",
       "      <td>Go</td>\n",
       "      <td>[Go, C, JavaScript, Objective-C, Java, GLSL, H...</td>\n",
       "      <td>2018-02-04T22:07:16Z</td>\n",
       "      <td>2025-03-09T22:42:59Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>everyone-can-use-english</td>\n",
       "      <td>25898</td>\n",
       "      <td>3848</td>\n",
       "      <td>25898</td>\n",
       "      <td>60</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>[TypeScript, Metal, Jupyter Notebook, HTML, Ja...</td>\n",
       "      <td>2019-03-15T16:33:53Z</td>\n",
       "      <td>2025-03-09T15:59:15Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>iced</td>\n",
       "      <td>25889</td>\n",
       "      <td>1248</td>\n",
       "      <td>25889</td>\n",
       "      <td>358</td>\n",
       "      <td>Rust</td>\n",
       "      <td>[Rust, WGSL, RenderScript]</td>\n",
       "      <td>2019-07-15T22:34:46Z</td>\n",
       "      <td>2025-03-09T22:08:30Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>awesome-datascience</td>\n",
       "      <td>25885</td>\n",
       "      <td>6018</td>\n",
       "      <td>25885</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2014-07-05T07:07:43Z</td>\n",
       "      <td>2025-03-09T16:04:09Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name   stars  forks  watchers  open_issues  \\\n",
       "0                freeCodeCamp  411063  39150    411063          253   \n",
       "1      free-programming-books  352089  62944    352089           87   \n",
       "2            build-your-own-x  351322  32580    351322          355   \n",
       "3                     awesome  350600  28668    350600           51   \n",
       "4                 public-apis  329757  34956    329757          470   \n",
       "..                        ...     ...    ...       ...          ...   \n",
       "995                 headscale   25915   1402     25915          117   \n",
       "996                      fyne   25901   1422     25901          699   \n",
       "997  everyone-can-use-english   25898   3848     25898           60   \n",
       "998                      iced   25889   1248     25889          358   \n",
       "999       awesome-datascience   25885   6018     25885            0   \n",
       "\n",
       "    primary_language                                          languages  \\\n",
       "0         TypeScript  [TypeScript, JavaScript, CSS, Dockerfile, EJS,...   \n",
       "1               HTML                                             [HTML]   \n",
       "2           Markdown                                         [Markdown]   \n",
       "3               None                                                 []   \n",
       "4             Python                                    [Python, Shell]   \n",
       "..               ...                                                ...   \n",
       "995               Go                   [Go, HTML, Nix, Shell, Makefile]   \n",
       "996               Go  [Go, C, JavaScript, Objective-C, Java, GLSL, H...   \n",
       "997       TypeScript  [TypeScript, Metal, Jupyter Notebook, HTML, Ja...   \n",
       "998             Rust                         [Rust, WGSL, RenderScript]   \n",
       "999             None                                                 []   \n",
       "\n",
       "               created_at            updated_at  \n",
       "0    2014-12-24T17:49:19Z  2025-03-09T22:38:20Z  \n",
       "1    2013-10-11T06:50:37Z  2025-03-09T22:44:06Z  \n",
       "2    2018-05-09T12:03:18Z  2025-03-09T22:51:09Z  \n",
       "3    2014-07-11T13:42:37Z  2025-03-09T22:46:56Z  \n",
       "4    2016-03-20T23:49:42Z  2025-03-09T22:50:53Z  \n",
       "..                    ...                   ...  \n",
       "995  2020-06-21T09:21:05Z  2025-03-09T22:36:14Z  \n",
       "996  2018-02-04T22:07:16Z  2025-03-09T22:42:59Z  \n",
       "997  2019-03-15T16:33:53Z  2025-03-09T15:59:15Z  \n",
       "998  2019-07-15T22:34:46Z  2025-03-09T22:08:30Z  \n",
       "999  2014-07-05T07:07:43Z  2025-03-09T16:04:09Z  \n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import concurrent.futures\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "HEADERS = {\"Authorization\": f\"token {GITHUB_TOKEN}\"}\n",
    "\n",
    "repos = []\n",
    "per_page = 100\n",
    "total_pages = 10\n",
    "\n",
    "# Récupération des dépôts avec pagination\n",
    "for page in range(1, total_pages + 1):\n",
    "    url = f\"https://api.github.com/search/repositories?q=stars:>10000&sort=stars&order=desc&per_page={per_page}&page={page}\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        repos.extend(data[\"items\"])\n",
    "    else:\n",
    "        print(f\"Erreur {response.status_code}: {response.text}\")\n",
    "        break\n",
    "\n",
    "    time.sleep(1)  # Pause légère pour éviter le rate limit\n",
    "\n",
    "# Fonction pour récupérer les langages\n",
    "def get_languages(repo):\n",
    "    lang_url = repo[\"languages_url\"]\n",
    "    response = requests.get(lang_url, headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        return {\n",
    "            \"name\": repo[\"name\"],\n",
    "            \"stars\": repo[\"stargazers_count\"],\n",
    "            \"forks\": repo[\"forks_count\"],\n",
    "            \"watchers\": repo[\"watchers_count\"],\n",
    "            \"open_issues\": repo[\"open_issues_count\"],\n",
    "            \"primary_language\": repo[\"language\"],\n",
    "            \"languages\": list(response.json().keys()),\n",
    "            \"created_at\": repo[\"created_at\"],\n",
    "            \"updated_at\": repo[\"updated_at\"]\n",
    "        }\n",
    "    return None\n",
    "\n",
    "# Exécution en parallèle pour récupérer les langages\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    enriched_repos = list(executor.map(get_languages, repos))\n",
    "\n",
    "# Filtrer les résultats valides\n",
    "enriched_repos = [repo for repo in enriched_repos if repo is not None]\n",
    "\n",
    "print(f\"Données enrichies récupérées : {len(enriched_repos)} dépôts\")\n",
    "\n",
    "df = pd.DataFrame(enriched_repos)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5152c9-4994-42e9-898c-cbaabf3373d7",
   "metadata": {},
   "source": [
    "### Kafka Producer (permet de récupérer les donnée depuis l'API Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f0fda39-26c0-4d30-b5f1-fb083252df1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Envoyé: freeCodeCamp\n",
      "Envoyé: free-programming-books\n",
      "Envoyé: build-your-own-x\n",
      "Envoyé: awesome\n",
      "Envoyé: public-apis\n",
      "Envoyé: coding-interview-university\n",
      "Envoyé: developer-roadmap\n",
      "Envoyé: system-design-primer\n",
      "Envoyé: 996.ICU\n",
      "Envoyé: awesome-python\n",
      "Envoyé: react\n",
      "Envoyé: project-based-learning\n",
      "Envoyé: awesome-selfhosted\n",
      "Envoyé: vue\n",
      "Envoyé: Python\n",
      "Envoyé: javascript-algorithms\n",
      "Envoyé: linux\n",
      "Envoyé: tensorflow\n",
      "Envoyé: You-Dont-Know-JS\n",
      "Envoyé: CS-Notes\n",
      "Envoyé: ohmyzsh\n",
      "Envoyé: computer-science\n",
      "Envoyé: AutoGPT\n",
      "Envoyé: bootstrap\n",
      "Envoyé: flutter\n",
      "Envoyé: vscode\n",
      "Envoyé: gitignore\n",
      "Envoyé: Python-100-Days\n",
      "Envoyé: the-book-of-secret-knowledge\n",
      "Envoyé: the-art-of-command-line\n",
      "Envoyé: stable-diffusion-webui\n",
      "Envoyé: JavaGuide\n",
      "Envoyé: javascript\n",
      "Envoyé: transformers\n",
      "Envoyé: awesome-go\n",
      "Envoyé: youtube-dl\n",
      "Envoyé: ollama\n",
      "Envoyé: next.js\n",
      "Envoyé: fucking-algorithm\n",
      "Envoyé: go\n",
      "Envoyé: Microsoft-Activation-Scripts\n",
      "Envoyé: 30-seconds-of-code\n",
      "Envoyé: tech-interview-handbook\n",
      "Envoyé: awesome-chatgpt-prompts\n",
      "Envoyé: react-native\n",
      "Envoyé: scrcpy\n",
      "Envoyé: PowerToys\n",
      "Envoyé: electron\n",
      "Envoyé: kubernetes\n",
      "Envoyé: free-programming-books-zh_CN\n",
      "Envoyé: node\n",
      "Envoyé: d3\n",
      "Envoyé: hello-algo\n",
      "Envoyé: axios\n",
      "Envoyé: three.js\n",
      "Envoyé: yt-dlp\n",
      "Envoyé: create-react-app\n",
      "Envoyé: langchain\n",
      "Envoyé: TypeScript\n",
      "Envoyé: deno\n",
      "Envoyé: nodebestpractices\n",
      "Envoyé: rust\n",
      "Envoyé: HelloGitHub\n",
      "Envoyé: terminal\n",
      "Envoyé: angular\n",
      "Envoyé: material-ui\n",
      "Envoyé: godot\n",
      "Envoyé: excalidraw\n",
      "Envoyé: ant-design\n",
      "Envoyé: free-for-dev\n",
      "Envoyé: clean-code-javascript\n",
      "Envoyé: DeepSeek-V3\n",
      "Envoyé: papers-we-love\n",
      "Envoyé: frp\n",
      "Envoyé: java-design-patterns\n",
      "Envoyé: iptv\n",
      "Envoyé: thefuck\n",
      "Envoyé: tauri\n",
      "Envoyé: puppeteer\n",
      "Envoyé: Awesome-Hacking\n",
      "Envoyé: vue-element-admin\n",
      "Envoyé: pytorch\n",
      "Envoyé: neovim\n",
      "Envoyé: every-programmer-should-know\n",
      "Envoyé: tailwindcss\n",
      "Envoyé: storybook\n",
      "Envoyé: DeepSeek-R1\n",
      "Envoyé: Web-Dev-For-Beginners\n",
      "Envoyé: rustdesk\n",
      "Envoyé: nvm\n",
      "Envoyé: django\n",
      "Envoyé: app-ideas\n",
      "Envoyé: ui\n",
      "Envoyé: bitcoin\n",
      "Envoyé: open-webui\n",
      "Envoyé: fastapi\n",
      "Envoyé: NextChat\n",
      "Envoyé: svelte\n",
      "Envoyé: animate.css\n",
      "Envoyé: realworld\n",
      "Envoyé: opencv\n",
      "Envoyé: awesome-mac\n",
      "Envoyé: gin\n",
      "Envoyé: laravel\n",
      "Envoyé: dify\n",
      "Envoyé: mall\n",
      "Envoyé: supabase\n",
      "Envoyé: hugo\n",
      "Envoyé: FiraCode\n",
      "Envoyé: whisper\n",
      "Envoyé: models\n",
      "Envoyé: advanced-java\n",
      "Envoyé: core\n",
      "Envoyé: bun\n",
      "Envoyé: mermaid\n",
      "Envoyé: spring-boot\n",
      "Envoyé: v2rayN\n",
      "Envoyé: llama.cpp\n",
      "Envoyé: manim\n",
      "Envoyé: LeetCodeAnimation\n",
      "Envoyé: Font-Awesome\n",
      "Envoyé: generative-ai-for-beginners\n",
      "Envoyé: json-server\n",
      "Envoyé: netdata\n",
      "Envoyé: awesome-interview-questions\n",
      "Envoyé: gpt4all\n",
      "Envoyé: awesome-vue\n",
      "Envoyé: awesome-for-beginners\n",
      "Envoyé: elasticsearch\n",
      "Envoyé: github-readme-stats\n",
      "Envoyé: funNLP\n",
      "Envoyé: ML-For-Beginners\n",
      "Envoyé: vite\n",
      "Envoyé: ComfyUI\n",
      "Envoyé: code-server\n",
      "Envoyé: devops-exercises\n",
      "Envoyé: playwright\n",
      "Envoyé: stable-diffusion\n",
      "Envoyé: nest\n",
      "Envoyé: Front-End-Checklist\n",
      "Envoyé: hoppscotch\n",
      "Envoyé: HowToCook\n",
      "Envoyé: moby\n",
      "Envoyé: system-design-101\n",
      "Envoyé: flask\n",
      "Envoyé: screenshot-to-code\n",
      "Envoyé: node\n",
      "Envoyé: fzf\n",
      "Envoyé: reveal.js\n",
      "Envoyé: cs-video-courses\n",
      "Envoyé: redis\n",
      "Envoyé: swift\n",
      "Envoyé: syncthing\n",
      "Envoyé: gpt_academic\n",
      "Envoyé: awesome-machine-learning\n",
      "Envoyé: awesome-react\n",
      "Envoyé: grafana\n",
      "Envoyé: protobuf\n",
      "Envoyé: d2l-zh\n",
      "Envoyé: express\n",
      "Envoyé: Best-websites-a-programmer-should-visit\n",
      "Envoyé: cpython\n",
      "Envoyé: uptime-kuma\n",
      "Envoyé: n8n\n",
      "Envoyé: Chart.js\n",
      "Envoyé: strapi\n",
      "Envoyé: Ventoy\n",
      "Envoyé: tesseract\n",
      "Envoyé: webpack\n",
      "Envoyé: superset\n",
      "Envoyé: 33-js-concepts\n",
      "Envoyé: ansible\n",
      "Envoyé: interviews\n",
      "Envoyé: gpt4free\n",
      "Envoyé: PayloadsAllTheThings\n",
      "Envoyé: imgui\n",
      "Envoyé: javascript-questions\n",
      "Envoyé: the-algorithm\n",
      "Envoyé: sherlock\n",
      "Envoyé: obs-studio\n",
      "Envoyé: keras\n",
      "Envoyé: sway\n",
      "Envoyé: tabby\n",
      "Envoyé: resume.github.com\n",
      "Envoyé: awesome-public-datasets\n",
      "Envoyé: awesome-cpp\n",
      "Envoyé: openai-cookbook\n",
      "Envoyé: caddy\n",
      "Envoyé: echarts\n",
      "Envoyé: socket.io\n",
      "Envoyé: nocode\n",
      "Envoyé: scikit-learn\n",
      "Envoyé: SecLists\n",
      "Envoyé: AppFlowy\n",
      "Envoyé: redux\n",
      "Envoyé: Java\n",
      "Envoyé: cs-self-learning\n",
      "Envoyé: Apollo-11\n",
      "Envoyé: awesome-scalability\n",
      "Envoyé: immich\n",
      "Envoyé: atom\n",
      "Envoyé: lodash\n",
      "Envoyé: design-resources-for-developers\n",
      "Envoyé: Front-end-Developer-Interview-Questions\n",
      "Envoyé: architect-awesome\n",
      "Envoyé: awesome-nodejs\n",
      "Envoyé: markdown-here\n",
      "Envoyé: jquery\n",
      "Envoyé: awesome-courses\n",
      "Envoyé: new-pac\n",
      "Envoyé: annotated_deep_learning_paper_implementations\n",
      "Envoyé: angular.js\n",
      "Envoyé: docusaurus\n",
      "Envoyé: shadowsocks-windows\n",
      "Envoyé: open-interpreter\n",
      "Envoyé: localsend\n",
      "Envoyé: act\n",
      "Envoyé: localstack\n",
      "Envoyé: alacritty\n",
      "Envoyé: llama\n",
      "Envoyé: fuel-core\n",
      "Envoyé: prometheus\n",
      "Envoyé: lazygit\n",
      "Envoyé: spring-framework\n",
      "Envoyé: lobe-chat\n",
      "Envoyé: html5-boilerplate\n",
      "Envoyé: rustlings\n",
      "Envoyé: nerd-fonts\n",
      "Envoyé: rails\n",
      "Envoyé: nuxt\n",
      "Envoyé: gatsby\n",
      "Envoyé: DeepLearning-500-questions\n",
      "Envoyé: private-gpt\n",
      "Envoyé: you-get\n",
      "Envoyé: zed\n",
      "Envoyé: ghidra\n",
      "Envoyé: leetcode\n",
      "Envoyé: awesome-flutter\n",
      "Envoyé: leetcode-master\n",
      "Envoyé: scrapy\n",
      "Envoyé: awesome-chatgpt-prompts-zh\n",
      "Envoyé: face_recognition\n",
      "Envoyé: react-router\n",
      "Envoyé: element\n",
      "Envoyé: tldr\n",
      "Envoyé: Prompt-Engineering-Guide\n",
      "Envoyé: git\n",
      "Envoyé: Real-Time-Voice-Cloning\n",
      "Envoyé: ChatGPT\n",
      "Envoyé: Stirling-PDF\n",
      "Envoyé: traefik\n",
      "Envoyé: faceswap\n",
      "Envoyé: gpt-engineer\n",
      "Envoyé: weekly\n",
      "Envoyé: drawio-desktop\n",
      "Envoyé: normalize.css\n",
      "Envoyé: openpilot\n",
      "Envoyé: nocodb\n",
      "Envoyé: yolov5\n",
      "Envoyé: requests\n",
      "Envoyé: mkcert\n",
      "Envoyé: hackingtool\n",
      "Envoyé: awesome-android-ui\n",
      "Envoyé: bat\n",
      "Envoyé: ionic-framework\n",
      "Envoyé: Magisk\n",
      "Envoyé: project-layout\n",
      "Envoyé: uBlock\n",
      "Envoyé: material-design-icons\n",
      "Envoyé: Semantic-UI\n",
      "Envoyé: rich\n",
      "Envoyé: anime\n",
      "Envoyé: ripgrep\n",
      "Envoyé: MetaGPT\n",
      "Envoyé: pi-hole\n",
      "Envoyé: langflow\n",
      "Envoyé: zustand\n",
      "Envoyé: minio\n",
      "Envoyé: guava\n",
      "Envoyé: grok-1\n",
      "Envoyé: kotlin\n",
      "Envoyé: clash-verge-rev\n",
      "Envoyé: prettier\n",
      "Envoyé: pdf.js\n",
      "Envoyé: Docker-OSX\n",
      "Envoyé: github-cheat-sheet\n",
      "Envoyé: dive\n",
      "Envoyé: OpenHands\n",
      "Envoyé: jekyll\n",
      "Envoyé: meilisearch\n",
      "Envoyé: bulma\n",
      "Envoyé: astro\n",
      "Envoyé: DefinitelyTyped\n",
      "Envoyé: rclone\n",
      "Envoyé: segment-anything\n",
      "Envoyé: awesome-rust\n",
      "Envoyé: core\n",
      "Envoyé: trackerslist\n",
      "Envoyé: marktext\n",
      "Envoyé: chinese-poetry\n",
      "Envoyé: Ghost\n",
      "Envoyé: etcd\n",
      "Envoyé: go-ethereum\n",
      "Envoyé: cypress\n",
      "Envoyé: awesome-ios\n",
      "Envoyé: powerlevel10k\n",
      "Envoyé: FFmpeg\n",
      "Envoyé: moment\n",
      "Envoyé: joplin\n",
      "Envoyé: hacker-scripts\n",
      "Envoyé: RxJava\n",
      "Envoyé: mastodon\n",
      "Envoyé: llm-course\n",
      "Envoyé: hiring-without-whiteboards\n",
      "Envoyé: appwrite\n",
      "Envoyé: dayjs\n",
      "Envoyé: gitea\n",
      "Envoyé: starship\n",
      "Envoyé: professional-programming\n",
      "Envoyé: ImHex\n",
      "Envoyé: first-contributions\n",
      "Envoyé: algorithm-visualizer\n",
      "Envoyé: PaddleOCR\n",
      "Envoyé: big-list-of-naughty-strings\n",
      "Envoyé: awesome-wechat-weapp\n",
      "Envoyé: Motrix\n",
      "Envoyé: alist\n",
      "Envoyé: PowerShell\n",
      "Envoyé: 100-Days-Of-ML-Code\n",
      "Envoyé: serverless\n",
      "Envoyé: julia\n",
      "Envoyé: AFFiNE\n",
      "Envoyé: okhttp\n",
      "Envoyé: design-patterns-for-humans\n",
      "Envoyé: react\n",
      "Envoyé: learn-regex\n",
      "Envoyé: Projects\n",
      "Envoyé: v2ray-core\n",
      "Envoyé: x64dbg\n",
      "Envoyé: gogs\n",
      "Envoyé: huginn\n",
      "Envoyé: 30-Days-Of-Python\n",
      "Envoyé: architecture-samples\n",
      "Envoyé: quill\n",
      "Envoyé: pandas\n",
      "Envoyé: pixijs\n",
      "Envoyé: terraform\n",
      "Envoyé: json\n",
      "Envoyé: type-challenges\n",
      "Envoyé: meteor\n",
      "Envoyé: jest\n",
      "Envoyé: Deep-Live-Cam\n",
      "Envoyé: AdminLTE\n",
      "Envoyé: pocketbase\n",
      "Envoyé: open-source-ios-apps\n",
      "Envoyé: query\n",
      "Envoyé: 30-Days-Of-JavaScript\n",
      "Envoyé: PythonDataScienceHandbook\n",
      "Envoyé: fuels-ts\n",
      "Envoyé: fuels-rs\n",
      "Envoyé: htmx\n",
      "Envoyé: awesome-react-components\n",
      "Envoyé: hyper\n",
      "Envoyé: parcel\n",
      "Envoyé: zx\n",
      "Envoyé: Fooocus\n",
      "Envoyé: TensorFlow-Examples\n",
      "Envoyé: LLaMA-Factory\n",
      "Envoyé: ragflow\n",
      "Envoyé: build-web-application-with-golang\n",
      "Envoyé: babel\n",
      "Envoyé: discourse\n",
      "Envoyé: CppCoreGuidelines\n",
      "Envoyé: retrofit\n",
      "Envoyé: frontend-dev-bookmarks\n",
      "Envoyé: jadx\n",
      "Envoyé: open-source-mac-os-apps\n",
      "Envoyé: awesome-java\n",
      "Envoyé: uv\n",
      "Envoyé: text-generation-webui\n",
      "Envoyé: lazydocker\n",
      "Envoyé: brew\n",
      "Envoyé: lx-music-desktop\n",
      "Envoyé: react-use\n",
      "Envoyé: kubernetes-the-hard-way\n",
      "Envoyé: react-hook-form\n",
      "Envoyé: union\n",
      "Envoyé: grpc\n",
      "Envoyé: front-end-interview-handbook\n",
      "Envoyé: vaultwarden\n",
      "Envoyé: Leaflet\n",
      "Envoyé: Rocket.Chat\n",
      "Envoyé: dbeaver\n",
      "Envoyé: maybe\n",
      "Envoyé: git-flight-rules\n",
      "Envoyé: GPT-SoVITS\n",
      "Envoyé: pm2\n",
      "Envoyé: awesome-cheatsheets\n",
      "Envoyé: JeecgBoot\n",
      "Envoyé: Alamofire\n",
      "Envoyé: edex-ui\n",
      "Envoyé: monaco-editor\n",
      "Envoyé: awesome-design-patterns\n",
      "Envoyé: LLMs-from-scratch\n",
      "Envoyé: acme.sh\n",
      "Envoyé: yarn\n",
      "Envoyé: prisma\n",
      "Envoyé: reactjs-interview-questions\n",
      "Envoyé: what-happens-when\n",
      "Envoyé: FreeDomain\n",
      "Envoyé: odoo\n",
      "Envoyé: metabase\n",
      "Envoyé: pyenv\n",
      "Envoyé: vue2-elm\n",
      "Envoyé: python-patterns\n",
      "Envoyé: ChatGLM-6B\n",
      "Envoyé: autogen\n",
      "Envoyé: vllm\n",
      "Envoyé: dubbo\n",
      "Envoyé: styled-components\n",
      "Envoyé: spark\n",
      "Envoyé: swiper\n",
      "Envoyé: ColossalAI\n",
      "Envoyé: anything-llm\n",
      "Envoyé: nw.js\n",
      "Envoyé: uni-app\n",
      "Envoyé: CPlusPlusThings\n",
      "Envoyé: stablediffusion\n",
      "Envoyé: diagrams\n",
      "Envoyé: kong\n",
      "Envoyé: vuetify\n",
      "Envoyé: ailearning\n",
      "Envoyé: sentry\n",
      "Envoyé: hexo\n",
      "Envoyé: fastlane\n",
      "Envoyé: nanoGPT\n",
      "Envoyé: nvm-windows\n",
      "Envoyé: black\n",
      "Envoyé: llama_index\n",
      "Envoyé: markitdown\n",
      "Envoyé: cobra\n",
      "Envoyé: iina\n",
      "Envoyé: termux-app\n",
      "Envoyé: ClickHouse\n",
      "Envoyé: fanqiang\n",
      "Envoyé: tldraw\n",
      "Envoyé: airflow\n",
      "Envoyé: cheat.sh\n",
      "Envoyé: v2rayNG\n",
      "Envoyé: materialize\n",
      "Envoyé: tabler\n",
      "Envoyé: Deep-Learning-Papers-Reading-Roadmap\n",
      "Envoyé: bert\n",
      "Envoyé: php-src\n",
      "Envoyé: chinese-independent-developer\n",
      "Envoyé: chakra-ui\n",
      "Envoyé: esbuild\n",
      "Envoyé: wrk\n",
      "Envoyé: video.js\n",
      "Envoyé: cli\n",
      "Envoyé: 50projects50days\n",
      "Envoyé: bevy\n",
      "Envoyé: whisper.cpp\n",
      "Envoyé: Made-With-ML\n",
      "Envoyé: mitmproxy\n",
      "Envoyé: TTS\n",
      "Envoyé: typst\n",
      "Envoyé: coolify\n",
      "Envoyé: FastChat\n",
      "Envoyé: streamlit\n",
      "Envoyé: tidb\n",
      "Envoyé: expo\n",
      "Envoyé: English-level-up-tips\n",
      "Envoyé: zju-icicles\n",
      "Envoyé: memos\n",
      "Envoyé: styleguide\n",
      "Envoyé: WeChatMsg\n",
      "Envoyé: EasySpider\n",
      "Envoyé: zig\n",
      "Envoyé: MPAndroidChart\n",
      "Envoyé: awesome-compose\n",
      "Envoyé: TrafficMonitor\n",
      "Envoyé: impress.js\n",
      "Envoyé: jellyfin\n",
      "Envoyé: gorm\n",
      "Envoyé: ultralytics\n",
      "Envoyé: phaser\n",
      "Envoyé: vim\n",
      "Envoyé: quivr\n",
      "Envoyé: browser-use\n",
      "Envoyé: free\n",
      "Envoyé: spotube\n",
      "Envoyé: DeepSpeed\n",
      "Envoyé: Open-Assistant\n",
      "Envoyé: preact\n",
      "Envoyé: leveldb\n",
      "Envoyé: jsoncrack.com\n",
      "Envoyé: freecodecamp.cn\n",
      "Envoyé: bark\n",
      "Envoyé: curl\n",
      "Envoyé: freqtrade\n",
      "Envoyé: awesome-remote-job\n",
      "Envoyé: tutorials\n",
      "Envoyé: shellcheck\n",
      "Envoyé: aria2\n",
      "Envoyé: python-cheatsheet\n",
      "Envoyé: ant-design-pro\n",
      "Envoyé: pure-bash-bible\n",
      "Envoyé: interview_internal_reference\n",
      "Envoyé: penpot\n",
      "Envoyé: tmux\n",
      "Envoyé: gradio\n",
      "Envoyé: OpenBB\n",
      "Envoyé: Pake\n",
      "Envoyé: photoprism\n",
      "Envoyé: istio\n",
      "Envoyé: ruff\n",
      "Envoyé: GitHubDaily\n",
      "Envoyé: Summer2025-Internships\n",
      "Envoyé: Files\n",
      "Envoyé: GFPGAN\n",
      "Envoyé: AI-For-Beginners\n",
      "Envoyé: novu\n",
      "Envoyé: JavaFamily\n",
      "Envoyé: trpc\n",
      "Envoyé: helix\n",
      "Envoyé: pandoc\n",
      "Envoyé: aspnetcore\n",
      "Envoyé: appsmith\n",
      "Envoyé: taro\n",
      "Envoyé: deeplearningbook-chinese\n",
      "Envoyé: v\n",
      "Envoyé: manifesto\n",
      "Envoyé: tesseract.js\n",
      "Envoyé: wtfpython\n",
      "Envoyé: arthas\n",
      "Envoyé: Flowise\n",
      "Envoyé: wtfjs\n",
      "Envoyé: zod\n",
      "Envoyé: MockingBird\n",
      "Envoyé: og-aws\n",
      "Envoyé: DragGAN\n",
      "Envoyé: ray\n",
      "Envoyé: lerna\n",
      "Envoyé: fd\n",
      "Envoyé: devdocs\n",
      "Envoyé: daisyui\n",
      "Envoyé: insomnia\n",
      "Envoyé: interview\n",
      "Envoyé: RSSHub\n",
      "Envoyé: googletest\n",
      "Envoyé: upscayl\n",
      "Envoyé: gym\n",
      "Envoyé: shadowsocks-android\n",
      "Envoyé: chatgpt-on-wechat\n",
      "Envoyé: hello-algorithm\n",
      "Envoyé: sheetjs\n",
      "Envoyé: date-fns\n",
      "Envoyé: fullPage.js\n",
      "Envoyé: koa\n",
      "Envoyé: slidev\n",
      "Envoyé: logseq\n",
      "Envoyé: fiber\n",
      "Envoyé: lottie-android\n",
      "Envoyé: Awesome-Design-Tools\n",
      "Envoyé: ladybird\n",
      "Envoyé: nativefier\n",
      "Envoyé: google-research\n",
      "Envoyé: 955.WLB\n",
      "Envoyé: lapce\n",
      "Envoyé: metasploit-framework\n",
      "Envoyé: ccxt\n",
      "Envoyé: typeorm\n",
      "Envoyé: ChatTTS\n",
      "Envoyé: awesome-react-native\n",
      "Envoyé: cli\n",
      "Envoyé: hackathon-starter\n",
      "Envoyé: carbon\n",
      "Envoyé: halo\n",
      "Envoyé: ToolJet\n",
      "Envoyé: compose\n",
      "Envoyé: system-design\n",
      "Envoyé: glide\n",
      "Envoyé: the-way-to-go_ZH_CN\n",
      "Envoyé: vim-plug\n",
      "Envoyé: HanLP\n",
      "Envoyé: TaskMatrix\n",
      "Envoyé: node-v0.x-archive\n",
      "Envoyé: node\n",
      "Envoyé: cal.com\n",
      "Envoyé: docs\n",
      "Envoyé: caffe\n",
      "Envoyé: ink-kit\n",
      "Envoyé: nushell\n",
      "Envoyé: formik\n",
      "Envoyé: clipboard.js\n",
      "Envoyé: marked\n",
      "Envoyé: spacedrive\n",
      "Envoyé: awesome-javascript\n",
      "Envoyé: Langchain-Chatchat\n",
      "Envoyé: 12306\n",
      "Envoyé: REKCARC-TSC-UHT\n",
      "Envoyé: gold-miner\n",
      "Envoyé: unsloth\n",
      "Envoyé: awesome-shell\n",
      "Envoyé: netty\n",
      "Envoyé: jieba\n",
      "Envoyé: react-beautiful-dnd\n",
      "Envoyé: cline\n",
      "Envoyé: shadowsocks\n",
      "Envoyé: faiss\n",
      "Envoyé: sqlmap\n",
      "Envoyé: AndroidUtilCode\n",
      "Envoyé: spring-boot-demo\n",
      "Envoyé: windows\n",
      "Envoyé: pytorch-image-models\n",
      "Envoyé: LeetCode-Go\n",
      "Envoyé: AFNetworking\n",
      "Envoyé: framework\n",
      "Envoyé: plane\n",
      "Envoyé: brackets\n",
      "Envoyé: leetcode\n",
      "Envoyé: AgentGPT\n",
      "Envoyé: husky\n",
      "Envoyé: XX-Net\n",
      "Envoyé: fastify\n",
      "Envoyé: easyexcel\n",
      "Envoyé: Coursera-ML-AndrewNg-Notes\n",
      "Envoyé: solid\n",
      "Envoyé: NewPipe\n",
      "Envoyé: zxing\n",
      "Envoyé: gulp\n",
      "Envoyé: payload\n",
      "Envoyé: milvus\n",
      "Envoyé: chatbox\n",
      "Envoyé: immutable-js\n",
      "Envoyé: siyuan\n",
      "Envoyé: JavaScript\n",
      "Envoyé: linux-command\n",
      "Envoyé: legado\n",
      "Envoyé: crawl4ai\n",
      "Envoyé: ijkplayer\n",
      "Envoyé: poetry\n",
      "Envoyé: carbon-lang\n",
      "Envoyé: Python\n",
      "Envoyé: ShadowsocksX-NG\n",
      "Envoyé: engineering-blogs\n",
      "Envoyé: harness\n",
      "Envoyé: gpt-pilot\n",
      "Envoyé: awesome-awesomeness\n",
      "Envoyé: zsh-autosuggestions\n",
      "Envoyé: material-design-lite\n",
      "Envoyé: LLM101n\n",
      "Envoyé: HEU_KMS_Activator\n",
      "Envoyé: polars\n",
      "Envoyé: portainer\n",
      "Envoyé: How-To-Ask-Questions-The-Smart-Way\n",
      "Envoyé: openpose\n",
      "Envoyé: certbot\n",
      "Envoyé: shardeum\n",
      "Envoyé: run\n",
      "Envoyé: vault\n",
      "Envoyé: beego\n",
      "Envoyé: chatgpt-web\n",
      "Envoyé: mattermost\n",
      "Envoyé: my-tv\n",
      "Envoyé: swc\n",
      "Envoyé: selenium\n",
      "Envoyé: RevokeMsgPatcher\n",
      "Envoyé: AnotherRedisDesktopManager\n",
      "Envoyé: modern-unix\n",
      "Envoyé: android-open-project\n",
      "Envoyé: bruno\n",
      "Envoyé: ControlNet\n",
      "Envoyé: jax\n",
      "Envoyé: awesome-docker\n",
      "Envoyé: detectron2\n",
      "Envoyé: graphql-engine\n",
      "Envoyé: nps\n",
      "Envoyé: C-Plus-Plus\n",
      "Envoyé: awesome-php\n",
      "Envoyé: jq\n",
      "Envoyé: yew\n",
      "Envoyé: serenity\n",
      "Envoyé: llvm-project\n",
      "Envoyé: OpenVoice\n",
      "Envoyé: learnGitBranching\n",
      "Envoyé: swr\n",
      "Envoyé: fairseq\n",
      "Envoyé: ShareX\n",
      "Envoyé: spaCy\n",
      "Envoyé: aseprite\n",
      "Envoyé: vimrc\n",
      "Envoyé: remote-jobs\n",
      "Envoyé: rxjs\n",
      "Envoyé: html2canvas\n",
      "Envoyé: HowToLiveLonger\n",
      "Envoyé: MS-DOS\n",
      "Envoyé: winutil\n",
      "Envoyé: full-stack-fastapi-template\n",
      "Envoyé: pnpm\n",
      "Envoyé: nacos\n",
      "Envoyé: jQuery-File-Upload\n",
      "Envoyé: lottie-web\n",
      "Envoyé: pytorch-tutorial\n",
      "Envoyé: LocalAI\n",
      "Envoyé: Blog\n",
      "Envoyé: outline\n",
      "Envoyé: remix\n",
      "Envoyé: etcher\n",
      "Envoyé: floating-ui\n",
      "Envoyé: WxJava\n",
      "Envoyé: dotfiles\n",
      "Envoyé: echo\n",
      "Envoyé: p3c\n",
      "Envoyé: v2ray-core\n",
      "Envoyé: cockroach\n",
      "Envoyé: libpku\n",
      "Envoyé: CyberChef\n",
      "Envoyé: rufus\n",
      "Envoyé: YesPlayMusic\n",
      "Envoyé: mmdetection\n",
      "Envoyé: manim\n",
      "Envoyé: slate\n",
      "Envoyé: Umi-OCR\n",
      "Envoyé: go-zero\n",
      "Envoyé: lede\n",
      "Envoyé: spring-boot-examples\n",
      "Envoyé: chatbot-ui\n",
      "Envoyé: linux-insides\n",
      "Envoyé: tabby\n",
      "Envoyé: NeteaseCloudMusicApi\n",
      "Envoyé: awesome-cto\n",
      "Envoyé: qBittorrent\n",
      "Envoyé: Sortable\n",
      "Envoyé: bulletproof-react\n",
      "Envoyé: refine\n",
      "Envoyé: calculator\n",
      "Envoyé: symfony\n",
      "Envoyé: dokku\n",
      "Envoyé: HEAD\n",
      "Envoyé: minikube\n",
      "Envoyé: interactive-coding-challenges\n",
      "Envoyé: webtorrent\n",
      "Envoyé: sharp\n",
      "Envoyé: layui\n",
      "Envoyé: lossless-cut\n",
      "Envoyé: Real-ESRGAN\n",
      "Envoyé: jsPDF\n",
      "Envoyé: bubbletea\n",
      "Envoyé: Reactive-Resume\n",
      "Envoyé: mpv\n",
      "Envoyé: stanford_alpaca\n",
      "Envoyé: fabric\n",
      "Envoyé: sequelize\n",
      "Envoyé: vue-cli\n",
      "Envoyé: stats\n",
      "Envoyé: foundation-sites\n",
      "Envoyé: fabric.js\n",
      "Envoyé: servo\n",
      "Envoyé: editor.js\n",
      "Envoyé: firecrawl\n",
      "Envoyé: influxdb\n",
      "Envoyé: AI-Expert-Roadmap\n",
      "Envoyé: kafka\n",
      "Envoyé: netron\n",
      "Envoyé: hutool\n",
      "Envoyé: leakcanary\n",
      "Envoyé: uppy\n",
      "Envoyé: project-guidelines\n",
      "Envoyé: comprehensive-rust\n",
      "Envoyé: react-boilerplate\n",
      "Envoyé: ruoyi-vue-pro\n",
      "Envoyé: phantomjs\n",
      "Envoyé: backstage\n",
      "Envoyé: OpenAPI-Specification\n",
      "Envoyé: directus\n",
      "Envoyé: roop\n",
      "Envoyé: tqdm\n",
      "Envoyé: 500lines\n",
      "Envoyé: Mr.-Ranedeer-AI-Tutor\n",
      "Envoyé: paper-reading\n",
      "Envoyé: particles.js\n",
      "Envoyé: GPTs\n",
      "Envoyé: apollo\n",
      "Envoyé: Hover\n",
      "Envoyé: data-engineering-zoomcamp\n",
      "Envoyé: awesome-macos-command-line\n",
      "Envoyé: standard\n",
      "Envoyé: rocksdb\n",
      "Envoyé: puter\n",
      "Envoyé: es6features\n",
      "Envoyé: algo\n",
      "Envoyé: MonitorControl\n",
      "Envoyé: alpine\n",
      "Envoyé: awesome-python-cn\n",
      "Envoyé: cheerio\n",
      "Envoyé: tiptap\n",
      "Envoyé: pytorch-lightning\n",
      "Envoyé: COVID-19\n",
      "Envoyé: folly\n",
      "Envoyé: cobalt\n",
      "Envoyé: CheatSheetSeries\n",
      "Envoyé: Data-Science-For-Beginners\n",
      "Envoyé: k3s\n",
      "Envoyé: weekly\n",
      "Envoyé: swift-algorithm-club\n",
      "Envoyé: numpy\n",
      "Envoyé: fish-shell\n",
      "Envoyé: croc\n",
      "Envoyé: docsify\n",
      "Envoyé: django-rest-framework\n",
      "Envoyé: aider\n",
      "Envoyé: mediapipe\n",
      "Envoyé: composer\n",
      "Envoyé: canal\n",
      "Envoyé: surrealdb\n",
      "Envoyé: Hello-Python\n",
      "Envoyé: css-protips\n",
      "Envoyé: k9s\n",
      "Envoyé: CasaOS\n",
      "Envoyé: server\n",
      "Envoyé: lux\n",
      "Envoyé: lighthouse\n",
      "Envoyé: consul\n",
      "Envoyé: todomvc\n",
      "Envoyé: python-guide\n",
      "Envoyé: postcss\n",
      "Envoyé: SpringAll\n",
      "Envoyé: slick\n",
      "Envoyé: linkedin-skill-assessments-quizzes\n",
      "Envoyé: react-spring\n",
      "Envoyé: Free-Certifications\n",
      "Envoyé: handson-ml2\n",
      "Envoyé: llama3\n",
      "Envoyé: vuex\n",
      "Envoyé: UTM\n",
      "Envoyé: xxl-job\n",
      "Envoyé: plyr\n",
      "Envoyé: machine-learning-for-software-engineers\n",
      "Envoyé: cursor\n",
      "Envoyé: Clone-Wars\n",
      "Envoyé: android_guides\n",
      "Envoyé: react-three-fiber\n",
      "Envoyé: tinygrad\n",
      "Envoyé: spring-cloud-alibaba\n",
      "Envoyé: async\n",
      "Envoyé: trilium\n",
      "Envoyé: DevToys\n",
      "Envoyé: JavaScript30\n",
      "Envoyé: the-super-tiny-compiler\n",
      "Envoyé: immer\n",
      "Envoyé: xyflow\n",
      "Envoyé: tuning_playbook\n",
      "Envoyé: backbone\n",
      "Envoyé: Complete-Python-3-Bootcamp\n",
      "Envoyé: filebrowser\n",
      "Envoyé: GPT_API_free\n",
      "Envoyé: druid\n",
      "Envoyé: stb\n",
      "Envoyé: tokio\n",
      "Envoyé: crewAI\n",
      "Envoyé: ChatGPT\n",
      "Envoyé: mantine\n",
      "Envoyé: nginxconfig.io\n",
      "Envoyé: viper\n",
      "Envoyé: medusa\n",
      "Envoyé: ghostty\n",
      "Envoyé: data-science-ipython-notebooks\n",
      "Envoyé: jan\n",
      "Envoyé: os-tutorial\n",
      "Envoyé: reverse-interview\n",
      "Envoyé: diffusers\n",
      "Envoyé: glances\n",
      "Envoyé: xstate\n",
      "Envoyé: react-select\n",
      "Envoyé: restic\n",
      "Envoyé: vnpy\n",
      "Envoyé: applied-ml\n",
      "Envoyé: DeepFaceLive\n",
      "Envoyé: waifu2x\n",
      "Envoyé: Charts\n",
      "Envoyé: mobx\n",
      "Envoyé: CLIP\n",
      "Envoyé: ink\n",
      "Envoyé: MinerU\n",
      "Envoyé: 90DaysOfDevOps\n",
      "Envoyé: it-tools\n",
      "Envoyé: Retrieval-based-Voice-Conversion-WebUI\n",
      "Envoyé: textual\n",
      "Envoyé: hosts\n",
      "Envoyé: vhr\n",
      "Envoyé: gitbook\n",
      "Envoyé: motion\n",
      "Envoyé: helm\n",
      "Envoyé: Xray-core\n",
      "Envoyé: yapi\n",
      "Envoyé: Jobs_Applier_AI_Agent_AIHawk\n",
      "Envoyé: ResumeSample\n",
      "Envoyé: Daily-Interview-Question\n",
      "Envoyé: python-fire\n",
      "Envoyé: dragonfly\n",
      "Envoyé: TrackersListCollection\n",
      "Envoyé: underscore\n",
      "Envoyé: awesome-sysadmin\n",
      "Envoyé: Python-programming-exercises\n",
      "Envoyé: AdGuardHome\n",
      "Envoyé: aos\n",
      "Envoyé: mindsdb\n",
      "Envoyé: weui\n",
      "Envoyé: firecracker\n",
      "Envoyé: duckdb\n",
      "Envoyé: Probabilistic-Programming-and-Bayesian-Methods-for-Hackers\n",
      "Envoyé: dnSpy\n",
      "Envoyé: turborepo\n",
      "Envoyé: mongoose\n",
      "Envoyé: wails\n",
      "Envoyé: anoma\n",
      "Envoyé: commander.js\n",
      "Envoyé: JCSprout\n",
      "Envoyé: Web\n",
      "Envoyé: Tvlist-awesome-m3u-m3u8\n",
      "Envoyé: python-telegram-bot\n",
      "Envoyé: tdesktop\n",
      "Envoyé: swagger-ui\n",
      "Envoyé: redash\n",
      "Envoyé: vue-vben-admin\n",
      "Envoyé: Avalonia\n",
      "Envoyé: codemirror5\n",
      "Envoyé: legacy-homebrew\n",
      "Envoyé: data-engineer-handbook\n",
      "Envoyé: twenty\n",
      "Envoyé: rust-course\n",
      "Envoyé: k6\n",
      "Envoyé: coder2gwy\n",
      "Envoyé: headlessui\n",
      "Envoyé: ace\n",
      "Envoyé: openssl\n",
      "Envoyé: mongo\n",
      "Envoyé: rethinkdb\n",
      "Envoyé: kit\n",
      "Envoyé: taichi\n",
      "Envoyé: angular-cli\n",
      "Envoyé: Faker\n",
      "Envoyé: drizzle-orm\n",
      "Envoyé: gitflow\n",
      "Envoyé: hangzhou_house_knowledge\n",
      "Envoyé: fastai\n",
      "Envoyé: so-vits-svc\n",
      "Envoyé: xgboost\n",
      "Envoyé: react-virtualized\n",
      "Envoyé: desktop\n",
      "Envoyé: awesome-deepseek-integration\n",
      "Envoyé: Rectangle\n",
      "Envoyé: khoj\n",
      "Envoyé: vscodium\n",
      "Envoyé: kitty\n",
      "Envoyé: cascadia-code\n",
      "Envoyé: vagrant\n",
      "Envoyé: create-t3-app\n",
      "Envoyé: 30-Days-Of-React\n",
      "Envoyé: spleeter\n",
      "Envoyé: srs\n",
      "Envoyé: nodemon\n",
      "Envoyé: GoodbyeDPI\n",
      "Envoyé: ChatDev\n",
      "Envoyé: the_silver_searcher\n",
      "Envoyé: quasar\n",
      "Envoyé: ExplorerPatcher\n",
      "Envoyé: Detectron\n",
      "Envoyé: miaosha\n",
      "Envoyé: emscripten\n",
      "Envoyé: nprogress\n",
      "Envoyé: Signal-Android\n",
      "Envoyé: cmder\n",
      "Envoyé: nginx\n",
      "Envoyé: exo\n",
      "Envoyé: next-auth\n",
      "Envoyé: jumpserver\n",
      "Envoyé: awesome-electron\n",
      "Envoyé: supervision\n",
      "Envoyé: fastText\n",
      "Envoyé: lottie-ios\n",
      "Envoyé: awesome-vscode\n",
      "Envoyé: darknet\n",
      "Envoyé: DeepSpeech\n",
      "Envoyé: ItChat\n",
      "Envoyé: go-patterns\n",
      "Envoyé: hacker-laws\n",
      "Envoyé: 1Panel\n",
      "Envoyé: llm.c\n",
      "Envoyé: select2\n",
      "Envoyé: refined-github\n",
      "Envoyé: table\n",
      "Envoyé: fonts\n",
      "Envoyé: headscale\n",
      "Envoyé: fyne\n",
      "Envoyé: everyone-can-use-english\n",
      "Envoyé: iced\n",
      "Envoyé: awesome-datascience\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaProducer\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "HEADERS = {\"Authorization\": f\"token {GITHUB_TOKEN}\"}\n",
    "KAFKA_TOPIC = \"github_repos\"\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=\"172.31.185.106:9092\",\n",
    "    value_serializer=lambda v: json.dumps(v).encode(\"utf-8\")\n",
    ")\n",
    "\n",
    "def fetch_github_repos():\n",
    "    repos = []\n",
    "    per_page = 100\n",
    "    total_pages = 10\n",
    "\n",
    "    for page in range(1, total_pages + 1):\n",
    "        url = f\"https://api.github.com/search/repositories?q=stars:>10000&sort=stars&order=desc&per_page={per_page}&page={page}\"\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            for repo in data[\"items\"]:\n",
    "                repo_data = {\n",
    "                    \"id\": repo[\"id\"],\n",
    "                    \"name\": repo[\"name\"],\n",
    "                    \"stars\": repo[\"stargazers_count\"],\n",
    "                    \"forks\": repo[\"forks_count\"],\n",
    "                    \"watchers\": repo[\"watchers_count\"],\n",
    "                    \"open_issues\": repo[\"open_issues_count\"],\n",
    "                    \"primary_language\": repo[\"language\"],\n",
    "                    \"languages_url\": repo[\"languages_url\"],\n",
    "                    \"created_at\": repo[\"created_at\"],\n",
    "                    \"updated_at\": repo[\"updated_at\"]\n",
    "                }\n",
    "                producer.send(KAFKA_TOPIC, repo_data)\n",
    "                print(f\"Envoyé: {repo_data['name']}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Erreur {response.status_code}: {response.text}\")\n",
    "            break\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "fetch_github_repos()\n",
    "producer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0a3a3d-201f-4626-83ef-0be9f492f2a5",
   "metadata": {},
   "source": [
    "### Kafka + Sauvegarde csv pyspark (teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e047bf-8437-466a-8356-974c77d4f7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connexion à Kafka...\n",
      "Consommateur Kafka connecté. En attente de messages...\n",
      "Message reçu: lodash - Messages: 1\n",
      "Message reçu: design-resources-for-developers - Messages: 2\n",
      "Message reçu: immich - Messages: 3\n",
      "Message reçu: architect-awesome - Messages: 4\n",
      "Message reçu: Front-end-Developer-Interview-Questions - Messages: 5\n",
      "Message reçu: markdown-here - Messages: 6\n",
      "Message reçu: awesome-nodejs - Messages: 7\n",
      "Message reçu: jquery - Messages: 8\n",
      "Message reçu: awesome-courses - Messages: 9\n",
      "Message reçu: new-pac - Messages: 10\n",
      "Message reçu: annotated_deep_learning_paper_implementations - Messages: 11\n",
      "Message reçu: angular.js - Messages: 12\n",
      "Message reçu: shadowsocks-windows - Messages: 13\n",
      "Message reçu: docusaurus - Messages: 14\n",
      "Message reçu: open-interpreter - Messages: 15\n",
      "Message reçu: localsend - Messages: 16\n",
      "Message reçu: act - Messages: 17\n",
      "Message reçu: localstack - Messages: 18\n",
      "Message reçu: alacritty - Messages: 19\n",
      "Message reçu: llama - Messages: 20\n",
      "Message reçu: fuel-core - Messages: 21\n",
      "Message reçu: prometheus - Messages: 22\n",
      "Message reçu: spring-framework - Messages: 23\n",
      "Message reçu: lazygit - Messages: 24\n",
      "Message reçu: lobe-chat - Messages: 25\n",
      "Message reçu: html5-boilerplate - Messages: 26\n",
      "Message reçu: rustlings - Messages: 27\n",
      "Message reçu: nerd-fonts - Messages: 28\n",
      "Message reçu: rails - Messages: 29\n",
      "Message reçu: nuxt - Messages: 30\n",
      "Message reçu: gatsby - Messages: 31\n",
      "Message reçu: DeepLearning-500-questions - Messages: 32\n",
      "Message reçu: private-gpt - Messages: 33\n",
      "Message reçu: you-get - Messages: 34\n",
      "Message reçu: leetcode - Messages: 35\n",
      "Message reçu: ghidra - Messages: 36\n",
      "Message reçu: zed - Messages: 37\n",
      "Message reçu: awesome-flutter - Messages: 38\n",
      "Message reçu: scrapy - Messages: 39\n",
      "Message reçu: awesome-chatgpt-prompts-zh - Messages: 40\n",
      "Message reçu: leetcode-master - Messages: 41\n",
      "Message reçu: face_recognition - Messages: 42\n",
      "Message reçu: react-router - Messages: 43\n",
      "Message reçu: element - Messages: 44\n",
      "Message reçu: tldr - Messages: 45\n",
      "Message reçu: Prompt-Engineering-Guide - Messages: 46\n",
      "Message reçu: git - Messages: 47\n",
      "Message reçu: ChatGPT - Messages: 48\n",
      "Message reçu: Real-Time-Voice-Cloning - Messages: 49\n",
      "Message reçu: traefik - Messages: 50\n",
      "Message reçu: faceswap - Messages: 51\n",
      "Message reçu: gpt-engineer - Messages: 52\n",
      "Message reçu: Stirling-PDF - Messages: 53\n",
      "Message reçu: weekly - Messages: 54\n",
      "Message reçu: drawio-desktop - Messages: 55\n",
      "Message reçu: normalize.css - Messages: 56\n",
      "Message reçu: openpilot - Messages: 57\n",
      "Message reçu: yolov5 - Messages: 58\n",
      "Message reçu: requests - Messages: 59\n",
      "Message reçu: nocodb - Messages: 60\n",
      "Message reçu: mkcert - Messages: 61\n",
      "Message reçu: hackingtool - Messages: 62\n",
      "Message reçu: awesome-android-ui - Messages: 63\n",
      "Message reçu: ionic-framework - Messages: 64\n",
      "Message reçu: bat - Messages: 65\n",
      "Message reçu: Magisk - Messages: 66\n",
      "Message reçu: project-layout - Messages: 67\n",
      "Message reçu: material-design-icons - Messages: 68\n",
      "Message reçu: Semantic-UI - Messages: 69\n",
      "Message reçu: rich - Messages: 70\n",
      "Message reçu: anime - Messages: 71\n",
      "Message reçu: ripgrep - Messages: 72\n",
      "Message reçu: pi-hole - Messages: 73\n",
      "Message reçu: zustand - Messages: 74\n",
      "Message reçu: guava - Messages: 75\n",
      "Message reçu: minio - Messages: 76\n",
      "Message reçu: uBlock - Messages: 77\n",
      "Message reçu: langflow - Messages: 78\n",
      "Message reçu: grok-1 - Messages: 79\n",
      "Message reçu: kotlin - Messages: 80\n",
      "Message reçu: prettier - Messages: 81\n",
      "Message reçu: pdf.js - Messages: 82\n",
      "Message reçu: Docker-OSX - Messages: 83\n",
      "Message reçu: github-cheat-sheet - Messages: 84\n",
      "Message reçu: dive - Messages: 85\n",
      "Message reçu: jekyll - Messages: 86\n",
      "Message reçu: bulma - Messages: 87\n",
      "Message reçu: meilisearch - Messages: 88\n",
      "Message reçu: astro - Messages: 89\n",
      "Message reçu: clash-verge-rev - Messages: 90\n",
      "Message reçu: DefinitelyTyped - Messages: 91\n",
      "Message reçu: rclone - Messages: 92\n",
      "Message reçu: segment-anything - Messages: 93\n",
      "Message reçu: core - Messages: 94\n",
      "Message reçu: awesome-rust - Messages: 95\n",
      "Message reçu: trackerslist - Messages: 96\n",
      "Message reçu: MetaGPT - Messages: 97\n",
      "Message reçu: chinese-poetry - Messages: 98\n",
      "Message reçu: marktext - Messages: 99\n",
      "Message reçu: OpenHands - Messages: 100\n",
      "Données écrites dans outputs/kafka_direct/github_repos_20250309_235848.csv\n",
      "Traitement terminé. 100 messages ont été traités.\n",
      "Consommateur Kafka fermé.\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "#Créer le dossier de sortie s'il n'existe pas\n",
    "output_dir = \"outputs/kafka_direct\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "#Nom du fichier de sortie avec timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_file = f\"{output_dir}/github_repos_{timestamp}.csv\"\n",
    "\n",
    "#Fonction pour écrire les données dans un fichier CSV\n",
    "def write_to_csv(records, filename):\n",
    "    if not records:\n",
    "        return\n",
    "    \n",
    "    #Extraire les en-têtes à partir des clés du premier enregistrement\n",
    "    headers = records[0].keys()\n",
    "    \n",
    "    #Écrire les données dans le fichier CSV\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=headers)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(records)\n",
    "    \n",
    "    print(f\"Données écrites dans {filename}\")\n",
    "\n",
    "#Configurer le consommateur Kafka\n",
    "print(\"Connexion à Kafka...\")\n",
    "try:\n",
    "    consumer = KafkaConsumer(\n",
    "        'github_repos',\n",
    "        bootstrap_servers=['172.31.185.106:9092'],\n",
    "        auto_offset_reset='earliest',\n",
    "        enable_auto_commit=True,\n",
    "        group_id='github_repos_group',\n",
    "        value_deserializer=lambda x: json.loads(x.decode('utf-8')),\n",
    "        consumer_timeout_ms=60000  # Timeout après 60 secondes sans message\n",
    "    )\n",
    "    \n",
    "    print(\"Consommateur Kafka connecté. En attente de messages...\")\n",
    "    \n",
    "    # Collecter les messages\n",
    "    records = []\n",
    "    count = 0\n",
    "    max_records = 100  # Limiter le nombre d'enregistrements pour le test\n",
    "    \n",
    "    for message in consumer:\n",
    "        data = message.value\n",
    "        records.append(data)\n",
    "        count += 1\n",
    "        \n",
    "        # Afficher les informations sur le message\n",
    "        print(f\"Message reçu: {data.get('name', 'Unknown')} - Messages: {count}\")\n",
    "        \n",
    "        # Sortir après avoir collecté un certain nombre de messages\n",
    "        if count >= max_records:\n",
    "            break\n",
    "    \n",
    "    # Écrire les résultats dans un fichier CSV\n",
    "    if records:\n",
    "        write_to_csv(records, output_file)\n",
    "        print(f\"Traitement terminé. {count} messages ont été traités.\")\n",
    "    else:\n",
    "        print(\"Aucun message n'a été reçu.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la connexion à Kafka: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Fermer le consommateur s'il a été créé\n",
    "    if 'consumer' in locals():\n",
    "        consumer.close()\n",
    "        print(\"Consommateur Kafka fermé.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55705e60-515e-4547-a6bf-3ac4315de401",
   "metadata": {},
   "source": [
    "### kafka Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a155e4e-3865-435a-9e92-baf93b5d5796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connexion à Kafka...\n",
      "Connexion à MongoDB réussie!\n",
      "Documents supprimés de MongoDB: 1000\n",
      "Consommateur Kafka connecté. En attente de messages...\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Erreur de parsing JSON: Expecting value: line 1 column 1 (char 0) - Message brut: b'oue batard oue'\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Lot de 10 documents inséré dans MongoDB\n",
      "Traitement terminé. 1000 messages ont été traités.\n",
      "Total de documents dans MongoDB: 1000\n",
      "Consommateur Kafka fermé.\n",
      "Connexion MongoDB fermée.\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Configuration MongoDB\n",
    "def connect_to_mongodb():\n",
    "    try:\n",
    "        client = MongoClient(\"mongodb+srv://ufacikfatih:byJlFI7t6Lb3CFyN@cluster0.krkuu.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
    "        db = client[\"Projet_BigData\"]\n",
    "        collection = db[\"Data_Kafka\"]\n",
    "        \n",
    "        client.admin.command('ping')\n",
    "        print(\"Connexion à MongoDB réussie!\")\n",
    "        \n",
    "        return client, db, collection\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur de connexion à MongoDB: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "print(\"Connexion à Kafka...\")\n",
    "try:\n",
    "    \n",
    "    client, db, collection = connect_to_mongodb()\n",
    "    \n",
    "    if collection is None:\n",
    "        raise Exception(\"Impossible de se connecter à MongoDB\")\n",
    "    \n",
    "    delete_result = collection.delete_many({})\n",
    "    print(f\"Documents supprimés de MongoDB: {delete_result.deleted_count}\")\n",
    "\n",
    "    consumer = KafkaConsumer(\n",
    "        'github_repos',\n",
    "        bootstrap_servers=['172.31.185.106:9092'],\n",
    "        auto_offset_reset='earliest',\n",
    "        enable_auto_commit=True,\n",
    "        group_id='github_repos_group',\n",
    "        consumer_timeout_ms=60000,\n",
    "        value_deserializer=lambda x: x  \n",
    "    )\n",
    "\n",
    "    print(\"Consommateur Kafka connecté. En attente de messages...\")\n",
    "\n",
    "    # Collecter les messages pour MongoDB\n",
    "    records = []\n",
    "    count = 0\n",
    "    max_records = 1000  \n",
    "    batch_size = 10  \n",
    "\n",
    "    for message in consumer:\n",
    "        raw_value = message.value\n",
    "\n",
    "        if not raw_value:  # Vérifie si le message est vide\n",
    "            print(\"Message vide reçu, passage au suivant.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            data = json.loads(raw_value.decode('utf-8'))  # Ajout du .decode()\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Erreur de parsing JSON: {e} - Message brut: {raw_value}\")\n",
    "            continue\n",
    "\n",
    "        # Ajouter un timestamp pour MongoDB\n",
    "        data['imported_at'] = datetime.now().isoformat()\n",
    "        records.append(data)\n",
    "        count += 1\n",
    "\n",
    "        # Insertion par lots pour optimiser les performances\n",
    "        if len(records) >= batch_size:\n",
    "            collection.insert_many(records)\n",
    "            print(f\"Lot de {len(records)} documents inséré dans MongoDB\")\n",
    "            records = []  \n",
    "\n",
    "        # Sortir après avoir collecté un certain nombre de messages\n",
    "        if count >= max_records:\n",
    "            break\n",
    "\n",
    "    # Insérer les documents restants\n",
    "    if records:\n",
    "        collection.insert_many(records)\n",
    "        print(f\"Dernier lot de {len(records)} documents inséré dans MongoDB\")\n",
    "\n",
    "    total_docs = collection.count_documents({})\n",
    "    print(f\"Traitement terminé. {count} messages ont été traités.\")\n",
    "    print(f\"Total de documents dans MongoDB: {total_docs}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du traitement: {e}\")\n",
    "\n",
    "finally:\n",
    "    if 'consumer' in locals():\n",
    "        consumer.close()\n",
    "        print(\"Consommateur Kafka fermé.\")\n",
    "\n",
    "    if 'client' in locals() and client is not None:\n",
    "        client.close()\n",
    "        print(\"Connexion MongoDB fermée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d497b1-88ef-4271-a57d-ba9b83bab0db",
   "metadata": {},
   "source": [
    "# Step 2 : Proposer une solution valorisant les données recueillies, grâce à l’IA, à destination d’entreprises, d’associations ou tout autre type d’organisation ainsi que des particuliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15728032-3d2c-4551-b1e3-3d3a397342a6",
   "metadata": {},
   "source": [
    "### Prediction avec interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5b18458-21b9-48e3-8bae-e71f6d6c5b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://b392e97002053d2582.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://b392e97002053d2582.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prétraitement terminé : 869 lignes et 15 colonnes restantes après nettoyage.\n",
      " Langages uniques après filtrage : 46\n",
      " Période couverte : 2008 - 2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:03:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:03:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:03:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:03:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:03:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:03:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:03:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:03:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:03:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:03:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:03:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:03:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:03:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:03:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:03:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:03:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:04:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:04:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:04:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:04:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:04:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:04:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:04:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:04:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:04:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:04:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:04:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:04:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:04:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:04:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:04:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:04:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:04:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:04:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:04:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:04:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:04:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:04:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:04:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:04:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prétraitement terminé : 869 lignes et 15 colonnes restantes après nettoyage.\n",
      " Langages uniques après filtrage : 46\n",
      " Période couverte : 2008 - 2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:05:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:05:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:05:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:05:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:05:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:05:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:05:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:05:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:05:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:05:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:05:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:05:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:05:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:06:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:06:23 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "from prophet import Prophet\n",
    "import warnings\n",
    "import os\n",
    "import gradio as gr\n",
    "import matplotlib\n",
    "import json\n",
    "matplotlib.use('Agg')  #Utiliser un backend non-interactif pour Gradio\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "#Connexion à MongoDB et récupération des données\n",
    "def get_data_from_mongodb():\n",
    "    try:\n",
    "        client = MongoClient(\"mongodb+srv://ufacikfatih:byJlFI7t6Lb3CFyN@cluster0.krkuu.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
    "        db = client[\"Projet_BigData\"]\n",
    "        collection = db[\"Data_Kafka\"]\n",
    "        \n",
    "      \n",
    "        data = list(collection.find({}))\n",
    "        \n",
    "        client.close()\n",
    "        return data, f\"Récupération réussie de {len(data)} documents depuis MongoDB\"\n",
    "    except Exception as e:\n",
    "        return [], f\"Erreur lors de la récupération des données: {e}\"\n",
    "\n",
    "#Prétraitement des données\n",
    "def preprocess_data(data):\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    if '_id' in df.columns:\n",
    "        df = df.drop('_id', axis=1)\n",
    "\n",
    "    for col in ['created_at', 'updated_at', 'imported_at']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "            df[col] = df[col].dt.tz_localize(None)\n",
    "\n",
    "    df = df[df['primary_language'].notna()]\n",
    "    \n",
    "    #Extraction des caractéristiques temporelles\n",
    "    if 'created_at' in df.columns:\n",
    "        df['repo_age_days'] = (datetime.now() - df['created_at']).dt.days\n",
    "        df['year_created'] = df['created_at'].dt.year\n",
    "        df['month_created'] = df['created_at'].dt.month\n",
    "\n",
    "    df = df[df['repo_age_days'] >= 0]\n",
    "\n",
    "    for col in ['stars', 'forks', 'watchers']:\n",
    "        if col in df.columns:\n",
    "            q99 = df[col].quantile(0.99) \n",
    "            df = df[df[col] <= q99] \n",
    "            \n",
    "    if all(col in df.columns for col in ['stars', 'forks', 'watchers', 'repo_age_days']):\n",
    "        df['engagement_score'] = (df['stars'] * 2 + df['forks'] * 3 + df['watchers']) / (df['repo_age_days'] + 1)\n",
    "\n",
    "    print(f\"\\n Prétraitement terminé : {df.shape[0]} lignes et {df.shape[1]} colonnes restantes après nettoyage.\")\n",
    "    print(f\" Langages uniques après filtrage : {df['primary_language'].nunique()}\")\n",
    "    print(f\" Période couverte : {df['year_created'].min()} - {df['year_created'].max()}\")\n",
    "    \n",
    "    return df, f\"Jeu de données prétraité avec {df.shape[0]} lignes et {df.shape[1]} colonnes\"\n",
    "\n",
    "#Analyse exploratoire des données\n",
    "def exploratory_analysis(df):\n",
    "    results = {}\n",
    "    \n",
    "    # Distribution des langages principaux\n",
    "    language_counts = df['primary_language'].value_counts().head(10)\n",
    "    results['language_counts'] = language_counts\n",
    "    \n",
    "    # Statistiques d'engagement par langage\n",
    "    language_stats = df.groupby('primary_language').agg({\n",
    "        'stars': 'mean',\n",
    "        'forks': 'mean',\n",
    "        'watchers': 'mean',\n",
    "        'engagement_score': 'mean',\n",
    "        'id': 'count'\n",
    "    }).sort_values('id', ascending=False).head(10)\n",
    "    language_stats.columns = ['Étoiles (moy)', 'Forks (moy)', 'Observateurs (moy)', 'Score d\\'engagement', 'Nombre de dépôts']\n",
    "    results['language_stats'] = language_stats\n",
    "    \n",
    "    #Tendance de création de dépôts par année\n",
    "    if 'year_created' in df.columns:\n",
    "        yearly_trend = df.groupby(['year_created', 'primary_language']).size().unstack().fillna(0)\n",
    "        results['yearly_trend'] = yearly_trend\n",
    "    \n",
    "    #Graphique en barres des principaux langages\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    language_counts.plot(kind='bar', color='skyblue')\n",
    "    plt.title('Top 10 des langages de programmation')\n",
    "    plt.xlabel('Langage')\n",
    "    plt.ylabel('Nombre de dépôts')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('top_languages.png')\n",
    "    plt.close()\n",
    "    \n",
    "    #Score d'engagement par langage\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    language_stats['Score d\\'engagement'].sort_values(ascending=False).plot(kind='bar', color='lightgreen')\n",
    "    plt.title('Score d\\'engagement moyen par langage')\n",
    "    plt.xlabel('Langage')\n",
    "    plt.ylabel('Score d\\'engagement')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('engagement_score.png')\n",
    "    plt.close()\n",
    "    \n",
    "    #Tendance annuelle\n",
    "    if 'yearly_trend' in results:\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        yearly_trend.sum(axis=1).plot(kind='line', marker='o')\n",
    "        plt.title('Création de dépôts par année')\n",
    "        plt.xlabel('Année')\n",
    "        plt.ylabel('Nombre de dépôts')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('yearly_trend.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return results, \"Analyse exploratoire terminée\"\n",
    "\n",
    "#Préparation des données pour le modèle de prédiction\n",
    "def prepare_for_prediction(df, top_languages=10):\n",
    "    # Sélection des langages les plus courants\n",
    "    top_langs = df['primary_language'].value_counts().head(top_languages).index.tolist()\n",
    "    df_top = df[df['primary_language'].isin(top_langs)].copy()\n",
    "    \n",
    "    # Création des séries temporelles pour chaque langage\n",
    "    if 'year_created' in df.columns:\n",
    "        time_series = df_top.groupby(['year_created', 'primary_language']).size().unstack().fillna(0)\n",
    "        \n",
    "        min_years_required = 4\n",
    "        valid_columns = []\n",
    "        \n",
    "        for col in time_series.columns:\n",
    "            non_zero_years = time_series[time_series[col] > 0].shape[0]\n",
    "            if non_zero_years >= min_years_required:\n",
    "                valid_columns.append(col)\n",
    "                \n",
    "        if not valid_columns:\n",
    "            return None, None, top_langs, \"Données temporelles insuffisantes pour la prédiction\"\n",
    "        \n",
    "        time_series = time_series[valid_columns]\n",
    "        \n",
    "        #Normalisation par le nombre total de dépôts par année\n",
    "        yearly_totals = time_series.sum(axis=1)\n",
    "        normalized_time_series = time_series.div(yearly_totals, axis=0) * 100\n",
    "        \n",
    "        #Visualisation des séries temporelles\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        for lang in valid_columns[:5]: \n",
    "            normalized_time_series[lang].plot(label=lang)\n",
    "        \n",
    "        plt.title('Popularité relative des principaux langages de programmation')\n",
    "        plt.xlabel('Année')\n",
    "        plt.ylabel('Pourcentage (%)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('language_trends.png')\n",
    "        plt.close()\n",
    "        \n",
    "        return time_series, normalized_time_series, valid_columns, \"Données de séries temporelles préparées pour la prédiction\"\n",
    "    else:\n",
    "        return None, None, top_langs, \"Données temporelles insuffisantes pour la prédiction\"\n",
    "\n",
    "#Modèle de prédiction Prophet pour chaque langage\n",
    "def build_prophet_models(time_series, normalized_time_series, top_langs, years_to_predict=5):\n",
    "    predictions = {}\n",
    "    normalized_predictions = {}\n",
    "    mape_scores = {}\n",
    "    \n",
    "    # Préparation des données pour Prophet\n",
    "    last_year = time_series.index.max()\n",
    "    model_results = []\n",
    "\n",
    "    for language in top_langs:\n",
    "        if language in time_series.columns:\n",
    "            lang_results = {\"language\": language}\n",
    "            \n",
    "            #Préparation des données au format Prophet (ds, y)\n",
    "            df_prophet = pd.DataFrame({\n",
    "                'ds': pd.to_datetime(time_series.index.astype(str) + '-01-01'),\n",
    "                'y': time_series[language].values\n",
    "            })\n",
    "            \n",
    "            df_prophet = df_prophet[df_prophet['y'] > 0].reset_index(drop=True)\n",
    "            \n",
    "            if len(df_prophet) < 5:\n",
    "                lang_results[\"status\"] = \"Données insuffisantes\"\n",
    "                model_results.append(lang_results)\n",
    "                continue\n",
    "            \n",
    "            #Création et entraînement du modèle\n",
    "            try:\n",
    "                model = Prophet(\n",
    "                    yearly_seasonality=True,\n",
    "                    seasonality_mode='multiplicative',\n",
    "                    changepoint_prior_scale=0.005,\n",
    "                    # Paramètres supplémentaires pour améliorer la robustesse\n",
    "                    changepoint_range=0.8,\n",
    "                    interval_width=0.8\n",
    "                )\n",
    "                \n",
    "                model.fit(df_prophet)\n",
    "                \n",
    "                # Fais les prédictions\n",
    "                future = model.make_future_dataframe(periods=years_to_predict, freq='Y')\n",
    "                forecast = model.predict(future)\n",
    "                \n",
    "                forecast['yhat'] = np.maximum(forecast['yhat'], 0)\n",
    "                forecast['yhat_lower'] = np.maximum(forecast['yhat_lower'], 0)\n",
    "                \n",
    "                #Stockage des prédictions\n",
    "                predictions[language] = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "                \n",
    "                #Calcul du MAPE sur les données historiques\n",
    "                historical_dates = df_prophet['ds'].values\n",
    "                forecast_historical = forecast[forecast['ds'].isin(historical_dates)]\n",
    "                \n",
    "                comparison = pd.merge(\n",
    "                    df_prophet[['ds', 'y']], \n",
    "                    forecast_historical[['ds', 'yhat']], \n",
    "                    on='ds'\n",
    "                )\n",
    "                \n",
    "                comparison = comparison[(comparison['y'] > 0) & (comparison['yhat'] > 0)]\n",
    "                \n",
    "                if not comparison.empty:\n",
    "                    abs_perc_errors = np.abs((comparison['y'] - comparison['yhat']) / comparison['y']) * 100\n",
    "                    mape = abs_perc_errors.mean()\n",
    "                    mape = min(mape, 100)  #MAPE à 100% pour une meilleure interprétation\n",
    "                    mape_scores[language] = mape\n",
    "                    lang_results[\"mape\"] = f\"{mape:.2f}%\"\n",
    "                \n",
    "                #Visualisation de la prédiction pour ce langage\n",
    "                fig = plt.figure(figsize=(10, 6))\n",
    "                ax = fig.add_subplot(111)\n",
    "                \n",
    "                #Tracer les données historiques\n",
    "                ax.plot(df_prophet['ds'], df_prophet['y'], 'ko', markersize=6, label='Réel')\n",
    "                \n",
    "                #Tracer la prédiction et l'intervalle de confiance\n",
    "                ax.plot(forecast['ds'], forecast['yhat'], 'steelblue', linewidth=2, label='Prévision')\n",
    "                ax.fill_between(forecast['ds'], forecast['yhat_lower'], forecast['yhat_upper'], color='steelblue', alpha=0.2)\n",
    "                \n",
    "                plt.title(f'Prédiction pour {language}')\n",
    "                plt.xlabel('Année')\n",
    "                plt.ylabel('Nombre de dépôts')\n",
    "                plt.legend()\n",
    "                plt.grid(True, linestyle='--', alpha=0.7)\n",
    "                plt.tight_layout()\n",
    "                \n",
    "                #Sauvegarder la figure pour chaque langage\n",
    "                fig_path = f'prediction_{language}.png'\n",
    "                plt.savefig(fig_path)\n",
    "                plt.close()\n",
    "                \n",
    "                lang_results[\"status\"] = \"Succès\"\n",
    "                lang_results[\"figure_path\"] = fig_path\n",
    "                \n",
    "                if language in normalized_time_series.columns:\n",
    "                    df_prophet_norm = pd.DataFrame({\n",
    "                        'ds': pd.to_datetime(normalized_time_series.index.astype(str) + '-01-01'),\n",
    "                        'y': normalized_time_series[language].values\n",
    "                    })\n",
    "                    \n",
    "                    df_prophet_norm = df_prophet_norm[df_prophet_norm['y'] > 0].reset_index(drop=True)\n",
    "                    \n",
    "                    if len(df_prophet_norm) >= 5:\n",
    "                        model_norm = Prophet(\n",
    "                            yearly_seasonality=True,\n",
    "                            seasonality_mode='multiplicative',\n",
    "                            changepoint_prior_scale=0.05,\n",
    "                            changepoint_range=0.8,\n",
    "                            interval_width=0.95\n",
    "                        )\n",
    "                        model_norm.fit(df_prophet_norm)\n",
    "                        \n",
    "                        future_norm = model_norm.make_future_dataframe(periods=years_to_predict, freq='Y')\n",
    "                        forecast_norm = model_norm.predict(future_norm)\n",
    "                        \n",
    "                        forecast_norm['yhat'] = np.clip(forecast_norm['yhat'], 0, 100)\n",
    "                        forecast_norm['yhat_lower'] = np.clip(forecast_norm['yhat_lower'], 0, 100)\n",
    "                        forecast_norm['yhat_upper'] = np.clip(forecast_norm['yhat_upper'], 0, 100)\n",
    "                        \n",
    "                        normalized_predictions[language] = forecast_norm[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "            \n",
    "            except Exception as e:\n",
    "                lang_results[\"status\"] = f\"Erreur: {str(e)}\"\n",
    "            \n",
    "            model_results.append(lang_results)\n",
    "    \n",
    "    #Section pour afficher les MAPE\n",
    "    mape_summary = \"\\n=== Erreur MAPE pour chaque langage ===\\n\"\n",
    "    for lang, mape in mape_scores.items():\n",
    "        mape_summary += f\"{lang}: {mape:.2f}%\\n\"\n",
    "    \n",
    "    #Visualisation combinée pour les principaux langages\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    for i, lang in enumerate(top_langs[:5]):  #5 principaux langages\n",
    "        if lang in normalized_predictions:\n",
    "            pred = normalized_predictions[lang]\n",
    "            plt.plot(pred['ds'], pred['yhat'], label=lang)\n",
    "            plt.fill_between(pred['ds'], pred['yhat_lower'], pred['yhat_upper'], alpha=0.2)\n",
    "    \n",
    "    plt.title('Part de marché relative prédite des langages de programmation')\n",
    "    plt.xlabel('Année')\n",
    "    plt.ylabel('Pourcentage relatif (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.savefig('language_predictions.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return predictions, normalized_predictions, model_results, f\"Modèles Prophet construits avec succès{mape_summary}\"\n",
    "\n",
    "#Générer des insights et des recommandations\n",
    "def generate_insights(time_series, normalized_predictions, top_langs, feature_importance):\n",
    "    insights = []\n",
    "    \n",
    "    #Langages en croissance vs en déclin\n",
    "    if normalized_predictions:\n",
    "        growth_rates = {}\n",
    "        \n",
    "        for lang in top_langs:\n",
    "            if lang in normalized_predictions:\n",
    "                pred = normalized_predictions[lang]\n",
    "                \n",
    "                future_values = pred[pred['ds'] > datetime.now()]\n",
    "                \n",
    "                if not future_values.empty and len(future_values) >= 2:\n",
    "                    start_value = future_values['yhat'].iloc[0]\n",
    "                    end_value = future_values['yhat'].iloc[-1]\n",
    "                    \n",
    "                    if start_value > 0:\n",
    "                        growth_rate = ((end_value - start_value) / start_value) * 100\n",
    "                        growth_rate = np.clip(growth_rate, -100, 500)\n",
    "                        growth_rates[lang] = growth_rate\n",
    "        \n",
    "        #Tri des langages par taux de croissance\n",
    "        sorted_growth = sorted(growth_rates.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        #Diviser clairement les langages en croissance et en déclin\n",
    "        growing_langs = [item for item in sorted_growth if item[1] > 0]\n",
    "        declining_langs = [item for item in sorted_growth if item[1] <= 0]\n",
    "        \n",
    "        insights.append(\"Langages avec la plus forte croissance prévue:\")\n",
    "        for lang, rate in growing_langs[:3]:\n",
    "            insights.append(f\"- {lang}: {rate:.2f}% de croissance relative attendue\")\n",
    "        \n",
    "        if not growing_langs:\n",
    "            insights.append(\"- Aucun langage avec une croissance positive identifiée\")\n",
    "        \n",
    "        insights.append(\"\\nLangages en déclin:\")\n",
    "        for lang, rate in declining_langs[:3]:\n",
    "            insights.append(f\"- {lang}: {rate:.2f}% de croissance relative attendue\")\n",
    "        \n",
    "        if not declining_langs:\n",
    "            insights.append(\"- Aucun langage en déclin identifié\")\n",
    "    \n",
    "    if feature_importance is not None:\n",
    "        lang_features = [f for f in feature_importance['Feature'] if f.startswith('lang_')]\n",
    "        \n",
    "        if lang_features:\n",
    "            top_lang_features = feature_importance[feature_importance['Feature'].isin(lang_features)]\n",
    "            \n",
    "            insights.append(\"\\nFacteurs de succès par langage:\")\n",
    "            for _, row in top_lang_features.head(5).iterrows():\n",
    "                lang_name = row['Feature'].replace('lang_', '')\n",
    "                insights.append(f\"- {lang_name}: Score d'importance {row['Importance']:.4f}\")\n",
    "    \n",
    "    # Recommandations générales\n",
    "    insights.append(\"\\nRecommandations pour les universités et les décideurs:\")\n",
    "    insights.append(\"1. Se concentrer sur l'enseignement des langages à forte croissance\")\n",
    "    insights.append(\"2. Intégrer des projets pratiques utilisant ces langages\")\n",
    "    insights.append(\"3. Développer des partenariats avec des entreprises utilisant ces technologies\")\n",
    "    insights.append(\"4. Surveiller l'évolution des écosystèmes autour de ces langages\")\n",
    "    \n",
    "    # Ajouter une section d'analyse de fiabilité\n",
    "    insights.append(\"\\nNote sur la fiabilité des prédictions:\")\n",
    "    insights.append(\"Les prédictions à long terme doivent être interprétées avec prudence.\")\n",
    "    insights.append(\"Les valeurs MAPE indiquent la précision du modèle (plus le pourcentage est bas, plus le modèle est précis).\")\n",
    "    insights.append(\"Les langages avec moins de points de données historiques peuvent avoir des prédictions moins fiables.\")\n",
    "    \n",
    "    return \"\\n\".join(insights)\n",
    "\n",
    "# Fonctions d'interface Gradio\n",
    "def fetch_data():\n",
    "    data, message = get_data_from_mongodb()\n",
    "    if not data:\n",
    "        return message, None, None, None\n",
    "    \n",
    "    df, preprocess_msg = preprocess_data(data)\n",
    "    \n",
    "    # Conversion du DataFrame en JSON pour stockage dans l'état Gradio\n",
    "    df_json = df.to_json(date_format='iso')\n",
    "    \n",
    "    return f\"{message}\\n{preprocess_msg}\", df.head(10).to_html(), f\"Total des enregistrements: {len(df)}\", df_json\n",
    "\n",
    "def run_analysis(df_json, top_n, prediction_years):\n",
    "    if not df_json:\n",
    "        return \"Aucune donnée disponible. Veuillez d'abord récupérer les données.\", None, None, None, None\n",
    "    \n",
    "    df = pd.read_json(df_json)\n",
    "    \n",
    "    top_n = int(top_n)\n",
    "    prediction_years = int(prediction_years)\n",
    "    \n",
    "    results, eda_msg = exploratory_analysis(df)\n",
    "    \n",
    "    # Préparation pour la prédiction\n",
    "    time_series, normalized_time_series, top_langs, prep_msg = prepare_for_prediction(df, top_languages=top_n)\n",
    "    \n",
    "    if time_series is None:\n",
    "        return f\"{eda_msg}\\n{prep_msg}\", \"top_languages.png\", \"engagement_score.png\", None, None\n",
    "    \n",
    "    predictions, normalized_predictions, model_results, prophet_msg = build_prophet_models(\n",
    "        time_series, normalized_time_series, top_langs, years_to_predict=prediction_years\n",
    "    )\n",
    "    \n",
    "    regression_model, scaler, feature_importance, model_metrics = build_regression_model(df, top_langs)\n",
    "    insights = generate_insights(time_series, normalized_predictions, top_langs, feature_importance)\n",
    "    \n",
    "    mape_table = \"<h3>Erreur MAPE par langage</h3><table>\"\n",
    "    mape_table += \"<tr><th>Langage</th><th>MAPE</th><th>Statut</th></tr>\"\n",
    "    \n",
    "    for result in model_results:\n",
    "        language = result.get(\"language\", \"\")\n",
    "        mape = result.get(\"mape\", \"N/A\")\n",
    "        status = result.get(\"status\", \"\")\n",
    "        mape_table += f\"<tr><td>{language}</td><td>{mape}</td><td>{status}</td></tr>\"\n",
    "    \n",
    "    mape_table += \"</table>\"\n",
    "    \n",
    "    status_message = f\"{eda_msg}\\n{prep_msg}\\n{prophet_msg}\"\n",
    "    if isinstance(model_metrics, dict):\n",
    "        status_message += f\"\\nMétriques du modèle de régression: {model_metrics}\"\n",
    "    else:\n",
    "        status_message += f\"\\n{model_metrics}\"\n",
    "    \n",
    "    insights_html = insights.replace(\"\\n\", \"<br>\")  \n",
    "    insights_html = f\"<p>{insights_html}</p>\"\n",
    "    \n",
    "    return status_message, \"top_languages.png\", \"language_trends.png\", \"language_predictions.png\",  insights_html, mape_table\n",
    "\n",
    "# Fonction build_regression_model\n",
    "def build_regression_model(df, top_langs):\n",
    "\n",
    "    df_model = df[df['primary_language'].isin(top_langs)].copy()\n",
    "    \n",
    "    df_model = pd.get_dummies(df_model, columns=['primary_language'], prefix='lang')\n",
    "    \n",
    "    # Sélection des caractéristiques et de la cible\n",
    "    features = ['repo_age_days', 'year_created'] + [col for col in df_model.columns if col.startswith('lang_')]\n",
    "    target = 'engagement_score'\n",
    "    \n",
    "    # Filtrage des caractéristiques disponibles\n",
    "    features = [f for f in features if f in df_model.columns]\n",
    "    \n",
    "    if not features or target not in df_model.columns:\n",
    "        return None, None, None, \"Données insuffisantes pour le modèle de régression\"\n",
    "    \n",
    "    X = df_model[features]\n",
    "    y = df_model[target]\n",
    "    \n",
    "    # Division entraînement/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Normalisation des caractéristiques\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Entraînement du modèle RandomForest\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Évaluation du modèle\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Importance des caractéristiques\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance.head(10))\n",
    "    plt.title('Importance des caractéristiques pour la prédiction du score d\\'engagement')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance.png')\n",
    "    plt.close()\n",
    "    \n",
    "    #Sauvegarde du modèle\n",
    "    joblib.dump(model, 'models/language_popularity_model.pkl')\n",
    "    joblib.dump(scaler, 'models/language_popularity_scaler.pkl')\n",
    "    \n",
    "    model_metrics = {\n",
    "        'RMSE': f\"{rmse:.4f}\",\n",
    "        'MAE': f\"{mae:.4f}\",\n",
    "        'R²': f\"{r2:.4f}\"\n",
    "    }\n",
    "    \n",
    "    return model, scaler, feature_importance, model_metrics\n",
    "\n",
    "# Créer l'interface Gradio\n",
    "def create_interface():\n",
    "    with gr.Blocks(title=\"Analyse des tendances des langages GitHub\") as app:\n",
    "        gr.Markdown(\"# Outil d'analyse des tendances des langages GitHub\")\n",
    "        gr.Markdown(\"Analysez et prédisez les tendances des langages de programmation basées sur les données des dépôts GitHub\")\n",
    "        \n",
    "        # État partagé pour le DataFrame\n",
    "        df_json = gr.State(value=None)\n",
    "        \n",
    "        with gr.Tab(\"Collecte de données\"):\n",
    "            fetch_btn = gr.Button(\"Récupérer les données depuis MongoDB\")\n",
    "            status_output = gr.Textbox(label=\"Statut\")\n",
    "            df_preview = gr.HTML(label=\"Aperçu des données\")\n",
    "            df_info = gr.Textbox(label=\"Infos du jeu de données\")\n",
    "            \n",
    "            fetch_btn.click(\n",
    "                fn=fetch_data,\n",
    "                outputs=[status_output, df_preview, df_info, df_json]\n",
    "            )\n",
    "        \n",
    "        with gr.Tab(\"Analyse & Prédiction\"):\n",
    "            with gr.Row():\n",
    "                top_n = gr.Slider(minimum=5, maximum=20, value=10, step=1, label=\"Nombre de langages principaux\")\n",
    "                prediction_years = gr.Slider(minimum=1, maximum=10, value=5, step=1, label=\"Années à prédire\")\n",
    "            \n",
    "            run_btn = gr.Button(\"Lancer l'analyse\")\n",
    "            \n",
    "            analysis_status = gr.Textbox(label=\"Statut de l'analyse\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                lang_dist_plot = gr.Image(label=\"Distribution des langages\")\n",
    "                trend_plot = gr.Image(label=\"Tendances des langages au fil du temps\")\n",
    "            \n",
    "            prediction_plot = gr.Image(label=\"Prédictions futures\")\n",
    "            \n",
    "            insights_output = gr.HTML(label=\"Insights & Recommandations\")\n",
    "            mape_output = gr.HTML(label=\"Erreur MAPE par langage\")\n",
    "\n",
    "            run_btn.click(\n",
    "                fn=run_analysis,\n",
    "                inputs=[df_json, top_n, prediction_years],\n",
    "                outputs=[analysis_status, lang_dist_plot, trend_plot, prediction_plot, insights_output, mape_output]\n",
    "            )\n",
    "    \n",
    "    return app\n",
    "    \n",
    "def main():\n",
    "    # Création de l'interface Gradio\n",
    "    app = create_interface()\n",
    "    \n",
    "    # Lancement de l'application\n",
    "    app.launch(share=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b63eda9-43f0-40f9-9291-e434d078cef7",
   "metadata": {},
   "source": [
    "# Step 3 : Proposer une solution d’évaluation et de monitoring de vos modèles ML "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97a7c4d-194a-4f71-a7ef-484fda7a2274",
   "metadata": {},
   "source": [
    "### Je n'ai pas eu le temps de finir cette partie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f3e95cb-3c95-43b8-85db-a9afc4c0de46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [14384]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "ERROR:    [Errno 10048] error while attempting to bind on address ('0.0.0.0', 8000): une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "Running on public URL: https://d4ec722d8d55af83d4.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d4ec722d8d55af83d4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:13:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:13:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:13:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:13:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:13:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:13:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:13:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:13:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:13:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:13:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:13:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:13:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:13:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:13:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:13:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:13:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:13:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:13:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:13:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      "23:13:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:13:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      "2025/03/09 23:14:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\miniconda3\\envs\\aag-talp\\lib\\site-packages\\gradio\\queueing.py\", line 536, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"D:\\miniconda3\\envs\\aag-talp\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"D:\\miniconda3\\envs\\aag-talp\\lib\\site-packages\\gradio\\blocks.py\", line 1935, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"D:\\miniconda3\\envs\\aag-talp\\lib\\site-packages\\gradio\\blocks.py\", line 1520, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"D:\\miniconda3\\envs\\aag-talp\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"D:\\miniconda3\\envs\\aag-talp\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"D:\\miniconda3\\envs\\aag-talp\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"D:\\miniconda3\\envs\\aag-talp\\lib\\site-packages\\gradio\\utils.py\", line 826, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\ufaci\\AppData\\Local\\Temp\\ipykernel_14384\\2374998836.py\", line 426, in run_evaluation\n",
      "    new_model, new_scaler, retrained, metrics_dict = evaluate_and_retrain(model, X_test, y_test, scaler, features, threshold=threshold, log_file=log_file)\n",
      "  File \"C:\\Users\\ufaci\\AppData\\Local\\Temp\\ipykernel_14384\\2374998836.py\", line 390, in evaluate_and_retrain\n",
      "    y_pred = model.predict(X_test_scaled)\n",
      "  File \"D:\\miniconda3\\envs\\aag-talp\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 1063, in predict\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"D:\\miniconda3\\envs\\aag-talp\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 641, in _validate_X_predict\n",
      "    X = self._validate_data(\n",
      "  File \"D:\\miniconda3\\envs\\aag-talp\\lib\\site-packages\\sklearn\\base.py\", line 654, in _validate_data\n",
      "    self._check_n_features(X, reset=reset)\n",
      "  File \"D:\\miniconda3\\envs\\aag-talp\\lib\\site-packages\\sklearn\\base.py\", line 443, in _check_n_features\n",
      "    raise ValueError(\n",
      "ValueError: X has 2 features, but RandomForestRegressor is expecting 12 features as input.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "from prophet import Prophet\n",
    "import warnings\n",
    "import os\n",
    "import gradio as gr\n",
    "import matplotlib\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Utiliser un backend non-interactif pour Gradio\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Créer les répertoires nécessaires\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('metrics', exist_ok=True)\n",
    "\n",
    "\n",
    "#Intégration de MLflow pour le suivi des métriques\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "def setup_mlflow_tracking():\n",
    "    mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "    mlflow.set_experiment(\"github_language_trends\")\n",
    "\n",
    "def log_model_metrics(metrics, model, params=None, artifacts=None):\n",
    "    with mlflow.start_run():\n",
    "        if params:\n",
    "            for key, value in params.items():\n",
    "                mlflow.log_param(key, value)\n",
    "        for key, value in metrics.items():\n",
    "            mlflow.log_metric(key, float(value))\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        if artifacts:\n",
    "            for name, path in artifacts.items():\n",
    "                mlflow.log_artifact(path, name)\n",
    "\n",
    "\n",
    "# Connexion à MongoDB et récupération des données\n",
    "\n",
    "def get_data_from_mongodb():\n",
    "    try:\n",
    "        client = MongoClient(\"mongodb+srv://ufacikfatih:byJlFI7t6Lb3CFyN@cluster0.krkuu.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
    "        db = client[\"Projet_BigData\"]\n",
    "        collection = db[\"Data_Kafka\"]\n",
    "        data = list(collection.find({}))\n",
    "        client.close()\n",
    "        return data, f\"Récupération réussie de {len(data)} documents depuis MongoDB\"\n",
    "    except Exception as e:\n",
    "        return [], f\"Erreur lors de la récupération des données: {e}\"\n",
    "\n",
    "\n",
    "# Prétraitement des données\n",
    "\n",
    "def preprocess_data(data):\n",
    "    df = pd.DataFrame(data)\n",
    "    if '_id' in df.columns:\n",
    "        df = df.drop('_id', axis=1)\n",
    "    if 'created_at' in df.columns:\n",
    "        df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "    if 'updated_at' in df.columns:\n",
    "        df['updated_at'] = pd.to_datetime(df['updated_at'])\n",
    "    if 'imported_at' in df.columns:\n",
    "        df['imported_at'] = pd.to_datetime(df['imported_at'])\n",
    "    if 'created_at' in df.columns:\n",
    "        df['created_at'] = df['created_at'].dt.tz_localize(None)\n",
    "    if 'updated_at' in df.columns:\n",
    "        df['updated_at'] = df['updated_at'].dt.tz_localize(None)\n",
    "    if 'imported_at' in df.columns:\n",
    "        df['imported_at'] = df['imported_at'].dt.tz_localize(None)\n",
    "    if 'created_at' in df.columns:\n",
    "        df['repo_age_days'] = (datetime.now() - df['created_at']).dt.days\n",
    "        df['year_created'] = df['created_at'].dt.year\n",
    "        df['month_created'] = df['created_at'].dt.month\n",
    "    df = df[df['primary_language'].notna()]\n",
    "    df['engagement_score'] = (df['stars'] * 2 + df['forks'] * 3 + df['watchers']) / (df['repo_age_days'] + 1)\n",
    "    return df, f\"Jeu de données prétraité avec {df.shape[0]} lignes et {df.shape[1]} colonnes\"\n",
    "\n",
    "\n",
    "# Analyse exploratoire des données\n",
    "\n",
    "def exploratory_analysis(df):\n",
    "    results = {}\n",
    "    language_counts = df['primary_language'].value_counts().head(10)\n",
    "    results['language_counts'] = language_counts\n",
    "    language_stats = df.groupby('primary_language').agg({\n",
    "        'stars': 'mean',\n",
    "        'forks': 'mean',\n",
    "        'watchers': 'mean',\n",
    "        'engagement_score': 'mean',\n",
    "        'id': 'count'\n",
    "    }).sort_values('id', ascending=False).head(10)\n",
    "    language_stats.columns = ['Étoiles (moy)', 'Forks (moy)', 'Observateurs (moy)', \"Score d'engagement\", 'Nombre de dépôts']\n",
    "    results['language_stats'] = language_stats\n",
    "    if 'year_created' in df.columns:\n",
    "        yearly_trend = df.groupby(['year_created', 'primary_language']).size().unstack().fillna(0)\n",
    "        results['yearly_trend'] = yearly_trend\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    language_counts.plot(kind='bar', color='skyblue')\n",
    "    plt.title('Top 10 des langages de programmation')\n",
    "    plt.xlabel('Langage')\n",
    "    plt.ylabel('Nombre de dépôts')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('top_languages.png')\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    language_stats[\"Score d'engagement\"].sort_values(ascending=False).plot(kind='bar', color='lightgreen')\n",
    "    plt.title(\"Score d'engagement moyen par langage\")\n",
    "    plt.xlabel('Langage')\n",
    "    plt.ylabel(\"Score d'engagement\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('engagement_score.png')\n",
    "    plt.close()\n",
    "    \n",
    "    if 'yearly_trend' in results:\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        yearly_trend.sum(axis=1).plot(kind='line', marker='o')\n",
    "        plt.title('Création de dépôts par année')\n",
    "        plt.xlabel('Année')\n",
    "        plt.ylabel('Nombre de dépôts')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('yearly_trend.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return results, \"Analyse exploratoire terminée\"\n",
    "\n",
    "\n",
    "# Préparation des données pour la prédiction\n",
    "\n",
    "def prepare_for_prediction(df, top_languages=10):\n",
    "    top_langs = df['primary_language'].value_counts().head(top_languages).index.tolist()\n",
    "    df_top = df[df['primary_language'].isin(top_langs)].copy()\n",
    "    if 'year_created' in df.columns:\n",
    "        time_series = df_top.groupby(['year_created', 'primary_language']).size().unstack().fillna(0)\n",
    "        min_years_required = 4\n",
    "        valid_columns = []\n",
    "        for col in time_series.columns:\n",
    "            if time_series[time_series[col] > 0].shape[0] >= min_years_required:\n",
    "                valid_columns.append(col)\n",
    "        if not valid_columns:\n",
    "            return None, None, top_langs, \"Données temporelles insuffisantes pour la prédiction\"\n",
    "        time_series = time_series[valid_columns]\n",
    "        yearly_totals = time_series.sum(axis=1)\n",
    "        normalized_time_series = time_series.div(yearly_totals, axis=0) * 100\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        for lang in valid_columns[:5]:\n",
    "            normalized_time_series[lang].plot(label=lang)\n",
    "        plt.title('Popularité relative des principaux langages de programmation')\n",
    "        plt.xlabel('Année')\n",
    "        plt.ylabel('Pourcentage (%)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('language_trends.png')\n",
    "        plt.close()\n",
    "        return time_series, normalized_time_series, valid_columns, \"Données de séries temporelles préparées pour la prédiction\"\n",
    "    else:\n",
    "        return None, None, top_langs, \"Données temporelles insuffisantes pour la prédiction\"\n",
    "\n",
    "\n",
    "# Modèle de prédiction Prophet pour chaque langage\n",
    "\n",
    "def build_prophet_models(time_series, normalized_time_series, top_langs, years_to_predict=5):\n",
    "    predictions = {}\n",
    "    normalized_predictions = {}\n",
    "    mape_scores = {}\n",
    "    model_results = []\n",
    "    # Utilisation de paramètres optimisés pour Prophet\n",
    "    prophet_params = {\"changepoint_prior_scale\": 0.02, \"changepoint_range\": 0.8, \"interval_width\": 0.95}\n",
    "    prophet_norm_params = {\"changepoint_prior_scale\": 0.05, \"changepoint_range\": 0.8, \"interval_width\": 0.95}\n",
    "    for language in top_langs:\n",
    "        if language in time_series.columns:\n",
    "            lang_results = {\"language\": language}\n",
    "            df_prophet = pd.DataFrame({\n",
    "                'ds': pd.to_datetime(time_series.index.astype(str) + '-01-01'),\n",
    "                'y': time_series[language].values\n",
    "            })\n",
    "            df_prophet = df_prophet[df_prophet['y'] > 0].reset_index(drop=True)\n",
    "            if len(df_prophet) < 5:\n",
    "                lang_results[\"status\"] = \"Données insuffisantes\"\n",
    "                model_results.append(lang_results)\n",
    "                continue\n",
    "            try:\n",
    "                model = Prophet(**prophet_params)\n",
    "                model.fit(df_prophet)\n",
    "                future = model.make_future_dataframe(periods=years_to_predict, freq='Y')\n",
    "                forecast = model.predict(future)\n",
    "                forecast['yhat'] = np.maximum(forecast['yhat'], 0)\n",
    "                forecast['yhat_lower'] = np.maximum(forecast['yhat_lower'], 0)\n",
    "                predictions[language] = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "                historical_dates = df_prophet['ds'].values\n",
    "                forecast_hist = forecast[forecast['ds'].isin(historical_dates)]\n",
    "                comparison = pd.merge(df_prophet[['ds', 'y']], forecast_hist[['ds', 'yhat']], on='ds')\n",
    "                comparison = comparison[(comparison['y'] > 0) & (comparison['yhat'] > 0)]\n",
    "                if not comparison.empty:\n",
    "                    abs_perc_errors = np.abs((comparison['y'] - comparison['yhat']) / comparison['y']) * 100\n",
    "                    mape = min(abs_perc_errors.mean(), 100)\n",
    "                    mape_scores[language] = mape\n",
    "                    lang_results[\"mape\"] = f\"{mape:.2f}%\"\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(df_prophet['ds'], df_prophet['y'], 'ko', markersize=6, label='Réel')\n",
    "                plt.plot(forecast['ds'], forecast['yhat'], 'steelblue', linewidth=2, label='Prévision')\n",
    "                plt.fill_between(forecast['ds'], forecast['yhat_lower'], forecast['yhat_upper'], color='steelblue', alpha=0.2)\n",
    "                plt.title(f'Prédiction pour {language}')\n",
    "                plt.xlabel('Année')\n",
    "                plt.ylabel('Nombre de dépôts')\n",
    "                plt.legend()\n",
    "                plt.grid(True, linestyle='--', alpha=0.7)\n",
    "                plt.tight_layout()\n",
    "                fig_path = f'prediction_{language}.png'\n",
    "                plt.savefig(fig_path)\n",
    "                plt.close()\n",
    "                lang_results[\"status\"] = \"Succès\"\n",
    "                lang_results[\"figure_path\"] = fig_path\n",
    "                if language in normalized_time_series.columns:\n",
    "                    df_prophet_norm = pd.DataFrame({\n",
    "                        'ds': pd.to_datetime(normalized_time_series.index.astype(str) + '-01-01'),\n",
    "                        'y': normalized_time_series[language].values\n",
    "                    })\n",
    "                    df_prophet_norm = df_prophet_norm[df_prophet_norm['y'] > 0].reset_index(drop=True)\n",
    "                    if len(df_prophet_norm) >= 5:\n",
    "                        model_norm = Prophet(**prophet_norm_params)\n",
    "                        model_norm.fit(df_prophet_norm)\n",
    "                        future_norm = model_norm.make_future_dataframe(periods=years_to_predict, freq='Y')\n",
    "                        forecast_norm = model_norm.predict(future_norm)\n",
    "                        forecast_norm['yhat'] = np.clip(forecast_norm['yhat'], 0, 100)\n",
    "                        forecast_norm['yhat_lower'] = np.clip(forecast_norm['yhat_lower'], 0, 100)\n",
    "                        forecast_norm['yhat_upper'] = np.clip(forecast_norm['yhat_upper'], 0, 100)\n",
    "                        normalized_predictions[language] = forecast_norm[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "            except Exception as e:\n",
    "                lang_results[\"status\"] = f\"Erreur: {str(e)}\"\n",
    "            model_results.append(lang_results)\n",
    "    mape_summary = \"\\n=== Erreur MAPE pour chaque langage ===\\n\"\n",
    "    for lang, mape in mape_scores.items():\n",
    "        mape_summary += f\"{lang}: {mape:.2f}%\\n\"\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for i, lang in enumerate(top_langs[:5]):\n",
    "        if lang in normalized_predictions:\n",
    "            pred = normalized_predictions[lang]\n",
    "            plt.plot(pred['ds'], pred['yhat'], label=lang)\n",
    "            plt.fill_between(pred['ds'], pred['yhat_lower'], pred['yhat_upper'], alpha=0.2)\n",
    "    plt.title('Part de marché relative prédite des langages de programmation')\n",
    "    plt.xlabel('Année')\n",
    "    plt.ylabel('Pourcentage relatif (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.savefig('language_predictions.png')\n",
    "    plt.close()\n",
    "    return predictions, normalized_predictions, model_results, f\"Modèles Prophet construits avec succès{mape_summary}\"\n",
    "\n",
    "# Générer des insights et recommandations\n",
    "\n",
    "def generate_insights(time_series, normalized_predictions, top_langs, feature_importance):\n",
    "    insights = []\n",
    "    if normalized_predictions:\n",
    "        growth_rates = {}\n",
    "        for lang in top_langs:\n",
    "            if lang in normalized_predictions:\n",
    "                pred = normalized_predictions[lang]\n",
    "                future_values = pred[pred['ds'] > datetime.now()]\n",
    "                if not future_values.empty and len(future_values) >= 2:\n",
    "                    start_value = future_values['yhat'].iloc[0]\n",
    "                    end_value = future_values['yhat'].iloc[-1]\n",
    "                    if start_value > 0:\n",
    "                        growth_rate = ((end_value - start_value) / start_value) * 100\n",
    "                        growth_rate = np.clip(growth_rate, -100, 500)\n",
    "                        growth_rates[lang] = growth_rate\n",
    "        sorted_growth = sorted(growth_rates.items(), key=lambda x: x[1], reverse=True)\n",
    "        growing_langs = [item for item in sorted_growth if item[1] > 0]\n",
    "        declining_langs = [item for item in sorted_growth if item[1] <= 0]\n",
    "        insights.append(\"Langages avec la plus forte croissance prévue:\")\n",
    "        for lang, rate in growing_langs[:3]:\n",
    "            insights.append(f\"- {lang}: {rate:.2f}% de croissance relative attendue\")\n",
    "        if not growing_langs:\n",
    "            insights.append(\"- Aucun langage avec une croissance positive identifiée\")\n",
    "        insights.append(\"\\nLangages en déclin:\")\n",
    "        for lang, rate in declining_langs[:3]:\n",
    "            insights.append(f\"- {lang}: {rate:.2f}% de croissance relative attendue\")\n",
    "        if not declining_langs:\n",
    "            insights.append(\"- Aucun langage en déclin identifié\")\n",
    "    if feature_importance is not None:\n",
    "        lang_features = [f for f in feature_importance['Feature'] if f.startswith('lang_')]\n",
    "        if lang_features:\n",
    "            top_lang_features = feature_importance[feature_importance['Feature'].isin(lang_features)]\n",
    "            insights.append(\"\\nFacteurs de succès par langage:\")\n",
    "            for _, row in top_lang_features.head(5).iterrows():\n",
    "                lang_name = row['Feature'].replace('lang_', '')\n",
    "                insights.append(f\"- {lang_name}: Score d'importance {row['Importance']:.4f}\")\n",
    "    insights.append(\"\\nRecommandations pour les universités et décideurs:\")\n",
    "    insights.append(\"1. Se concentrer sur l'enseignement des langages à forte croissance\")\n",
    "    insights.append(\"2. Intégrer des projets pratiques utilisant ces langages\")\n",
    "    insights.append(\"3. Développer des partenariats avec des entreprises technologiques\")\n",
    "    insights.append(\"4. Surveiller l'évolution des écosystèmes autour de ces langages\")\n",
    "    insights.append(\"\\nNote sur la fiabilité des prédictions:\")\n",
    "    insights.append(\"Les prédictions à long terme doivent être interprétées avec prudence.\")\n",
    "    insights.append(\"Les valeurs MAPE indiquent la précision du modèle (plus le pourcentage est bas, plus le modèle est précis).\")\n",
    "    insights.append(\"Les langages avec moins de points de données historiques peuvent avoir des prédictions moins fiables.\")\n",
    "    return \"\\n\".join(insights)\n",
    "\n",
    "\n",
    "# Modèle de régression (avec GridSearchCV)\n",
    "\n",
    "def build_regression_model(df, top_langs):\n",
    "    df_model = df[df['primary_language'].isin(top_langs)].copy()\n",
    "    df_model = pd.get_dummies(df_model, columns=['primary_language'], prefix='lang')\n",
    "    features = ['repo_age_days', 'year_created'] + [col for col in df_model.columns if col.startswith('lang_')]\n",
    "    target = 'engagement_score'\n",
    "    features = [f for f in features if f in df_model.columns]\n",
    "    if not features or target not in df_model.columns:\n",
    "        return None, None, None, \"Données insuffisantes pour le modèle de régression\"\n",
    "    X = df_model[features]\n",
    "    y = df_model[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10, 20]\n",
    "    }\n",
    "    rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "    grid_search = GridSearchCV(rf, param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': best_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance.head(10))\n",
    "    plt.title(\"Importance des caractéristiques pour la prédiction du score d'engagement\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance.png')\n",
    "    plt.close()\n",
    "    joblib.dump(best_model, 'models/language_popularity_model.pkl')\n",
    "    joblib.dump(scaler, 'models/language_popularity_scaler.pkl')\n",
    "    model_metrics = {\n",
    "        'RMSE': f\"{rmse:.4f}\",\n",
    "        'MAE': f\"{mae:.4f}\",\n",
    "        'R²': f\"{r2:.4f}\"\n",
    "    }\n",
    "    log_model_metrics(model_metrics, best_model, params={\"top_langs\": top_langs}, artifacts={\"feature_importance\": \"feature_importance.png\"})\n",
    "    return best_model, scaler, feature_importance, model_metrics\n",
    "\n",
    "\n",
    "# Fonctions de monitoring et réentraînement\n",
    "\n",
    "def setup_model_monitoring(model_name):\n",
    "    os.makedirs('metrics', exist_ok=True)\n",
    "    log_file = f'metrics/{model_name}_performance.csv'\n",
    "    if not os.path.exists(log_file):\n",
    "        with open(log_file, 'w') as f:\n",
    "            f.write('timestamp,rmse,mae,r2,data_drift_score,concept_drift_detected\\n')\n",
    "    return log_file\n",
    "\n",
    "def detect_data_drift(X_reference, X_current, threshold=0.05):\n",
    "    from scipy import stats\n",
    "    drift_scores = {}\n",
    "    drift_detected = False\n",
    "    for feature in X_reference.columns:\n",
    "        if X_reference[feature].dtype in [np.float64, np.int64]:\n",
    "            ks_stat, p_value = stats.ks_2samp(X_reference[feature], X_current[feature])\n",
    "            drift_scores[feature] = ks_stat\n",
    "            if p_value < threshold:\n",
    "                drift_detected = True\n",
    "    avg_drift_score = np.mean(list(drift_scores.values()))\n",
    "    return drift_detected, avg_drift_score, drift_scores\n",
    "\n",
    "def evaluate_and_retrain(model, X_test, y_test, scaler, features, threshold=0.1, log_file=None):\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    X_reference = joblib.load('models/reference_data.pkl') if os.path.exists('models/reference_data.pkl') else X_test\n",
    "    drift_detected, drift_score, _ = detect_data_drift(X_reference, X_test)\n",
    "    if log_file:\n",
    "        with open(log_file, 'a') as f:\n",
    "            f.write(f\"{datetime.now().isoformat()},{rmse},{mae},{r2},{drift_score},{drift_detected}\\n\")\n",
    "    should_retrain = (r2 < threshold) or drift_detected\n",
    "    if should_retrain:\n",
    "        data, _ = get_data_from_mongodb()\n",
    "        df, _ = preprocess_data(data)\n",
    "        new_model, new_scaler, _, _ = build_regression_model(df, features)\n",
    "        joblib.dump(new_model, 'models/language_popularity_model.pkl')\n",
    "        joblib.dump(new_scaler, 'models/language_popularity_scaler.pkl')\n",
    "        joblib.dump(X_test, 'models/reference_data.pkl')\n",
    "        return new_model, new_scaler, True, {'RMSE': rmse, 'MAE': mae, 'R²': r2}\n",
    "    return model, scaler, False, {'RMSE': rmse, 'MAE': mae, 'R²': r2}\n",
    "\n",
    "def run_evaluation(model_name, threshold, df_json):\n",
    "    if not df_json:\n",
    "        return \"Aucune donnée disponible pour l'évaluation.\", \"top_languages.png\", \"yearly_trend.png\"\n",
    "    df = pd.read_json(df_json)\n",
    "    features = ['repo_age_days', 'year_created'] + [col for col in df.columns if col.startswith('lang_')]\n",
    "    features = [f for f in features if f in df.columns]\n",
    "    target = 'engagement_score'\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    try:\n",
    "        model = joblib.load('models/language_popularity_model.pkl')\n",
    "    except Exception as e:\n",
    "        return f\"Erreur lors du chargement du modèle: {e}\", \"top_languages.png\", \"yearly_trend.png\"\n",
    "    log_file = setup_model_monitoring(model_name)\n",
    "    new_model, new_scaler, retrained, metrics_dict = evaluate_and_retrain(model, X_test, y_test, scaler, features, threshold=threshold, log_file=log_file)\n",
    "    status = f\"Évaluation terminée. Réentraînement {'effectué' if retrained else 'non nécessaire'}. Metrics: {metrics_dict}\"\n",
    "    return status, \"top_languages.png\", \"yearly_trend.png\"\n",
    "\n",
    "# Fonctions pour l'apprentissage en streaming\n",
    "\n",
    "def setup_streaming_model(features):\n",
    "    from river import forest, compose, preprocessing, metrics as river_metrics\n",
    "    model = compose.Pipeline(\n",
    "        preprocessing.StandardScaler(),\n",
    "        forest.AMFRegressor(n_models=10, seed=42)\n",
    "    )\n",
    "    metric = river_metrics.RollingRMSE(window_size=100)\n",
    "    return model, metric\n",
    "\n",
    "def update_streaming_model(stream_model, metric, features, target):\n",
    "    x = {feature: features[feature] for feature in features.index}\n",
    "    y_pred = stream_model.predict_one(x)\n",
    "    if target is not None:\n",
    "        metric.update(target, y_pred)\n",
    "        stream_model.learn_one(x, target)\n",
    "    return stream_model, metric, y_pred\n",
    "\n",
    "def start_streaming():\n",
    "    stream_model, metric = setup_streaming_model([])\n",
    "    for i in range(10):\n",
    "        fake_features = pd.Series({'repo_age_days': np.random.randint(1, 1000), 'year_created': np.random.randint(2000, 2023)})\n",
    "        fake_target = np.random.random() * 100\n",
    "        stream_model, metric, y_pred = update_streaming_model(stream_model, metric, fake_features, fake_target)\n",
    "        time.sleep(0.5)\n",
    "    status = \"Le modèle de streaming a été mis à jour avec des données simulées.\"\n",
    "    return status, \"language_trends.png\"\n",
    "\n",
    "\n",
    "# Interface FastAPI pour la prédiction en temps réel\n",
    "\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import uvicorn\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "class DataPoint(BaseModel):\n",
    "    features: dict\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict(data: DataPoint):\n",
    "    try:\n",
    "        model = joblib.load('models/language_popularity_model.pkl')\n",
    "        scaler = joblib.load('models/language_popularity_scaler.pkl')\n",
    "        features = pd.DataFrame([data.features])\n",
    "        features_scaled = scaler.transform(features)\n",
    "        prediction = model.predict(features_scaled)[0]\n",
    "        return {\"prediction\": prediction}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "def start_prediction_service():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "\n",
    "\n",
    "# Fonctions d'interface Gradio\n",
    "\n",
    "def fetch_data():\n",
    "    data, message = get_data_from_mongodb()\n",
    "    if not data:\n",
    "        return message, None, None, None\n",
    "    df, preprocess_msg = preprocess_data(data)\n",
    "    df_json = df.to_json(date_format='iso')\n",
    "    return f\"{message}\\n{preprocess_msg}\", df.head(10).to_html(), f\"Total des enregistrements: {len(df)}\", df_json\n",
    "\n",
    "def run_analysis(df_json, top_n, prediction_years):\n",
    "    if not df_json:\n",
    "        return \"Aucune donnée disponible. Veuillez d'abord récupérer les données.\", None, None, None, None\n",
    "    df = pd.read_json(df_json)\n",
    "    top_n = int(top_n)\n",
    "    prediction_years = int(prediction_years)\n",
    "    results, eda_msg = exploratory_analysis(df)\n",
    "    time_series, normalized_time_series, top_langs, prep_msg = prepare_for_prediction(df, top_languages=top_n)\n",
    "    if time_series is None:\n",
    "        return f\"{eda_msg}\\n{prep_msg}\", \"top_languages.png\", \"engagement_score.png\", None, None\n",
    "    predictions, normalized_predictions, model_results, prophet_msg = build_prophet_models(\n",
    "        time_series, normalized_time_series, top_langs, years_to_predict=prediction_years\n",
    "    )\n",
    "    regression_model, scaler, feature_importance, model_metrics = build_regression_model(df, top_langs)\n",
    "    insights = generate_insights(time_series, normalized_predictions, top_langs, feature_importance)\n",
    "    mape_table = \"<h3>Erreur MAPE par langage</h3><table>\"\n",
    "    mape_table += \"<tr><th>Langage</th><th>MAPE</th><th>Statut</th></tr>\"\n",
    "    for result in model_results:\n",
    "        language = result.get(\"language\", \"\")\n",
    "        mape = result.get(\"mape\", \"N/A\")\n",
    "        status = result.get(\"status\", \"\")\n",
    "        mape_table += f\"<tr><td>{language}</td><td>{mape}</td><td>{status}</td></tr>\"\n",
    "    mape_table += \"</table>\"\n",
    "    status_message = f\"{eda_msg}\\n{prep_msg}\\n{prophet_msg}\"\n",
    "    if isinstance(model_metrics, dict):\n",
    "        status_message += f\"\\nMétriques du modèle de régression: {model_metrics}\"\n",
    "    else:\n",
    "        status_message += f\"\\n{model_metrics}\"\n",
    "    insights += \"\\n\\n\" + mape_table\n",
    "    return status_message, \"top_languages.png\", \"language_trends.png\", \"language_predictions.png\", insights\n",
    "\n",
    "def create_interface():\n",
    "    with gr.Blocks(title=\"Analyse des tendances des langages GitHub\") as app:\n",
    "        gr.Markdown(\"# Outil d'analyse des tendances des langages GitHub\")\n",
    "        gr.Markdown(\"Analysez et prédisez les tendances des langages de programmation basées sur les données des dépôts GitHub\")\n",
    "        df_json = gr.State(value=None)\n",
    "        \n",
    "        with gr.Tab(\"Collecte de données\"):\n",
    "            fetch_btn = gr.Button(\"Récupérer les données depuis MongoDB\")\n",
    "            status_output = gr.Textbox(label=\"Statut\")\n",
    "            df_preview = gr.HTML(label=\"Aperçu des données\")\n",
    "            df_info = gr.Textbox(label=\"Infos du jeu de données\")\n",
    "            fetch_btn.click(\n",
    "                fn=fetch_data,\n",
    "                outputs=[status_output, df_preview, df_info, df_json]\n",
    "            )\n",
    "        \n",
    "        with gr.Tab(\"Analyse & Prédiction\"):\n",
    "            with gr.Row():\n",
    "                top_n = gr.Slider(minimum=5, maximum=20, value=10, step=1, label=\"Nombre de langages principaux\")\n",
    "                prediction_years = gr.Slider(minimum=1, maximum=10, value=5, step=1, label=\"Années à prédire\")\n",
    "            run_btn = gr.Button(\"Lancer l'analyse\")\n",
    "            analysis_status = gr.Textbox(label=\"Statut de l'analyse\")\n",
    "            with gr.Row():\n",
    "                lang_dist_plot = gr.Image(label=\"Distribution des langages\")\n",
    "                trend_plot = gr.Image(label=\"Tendances des langages au fil du temps\")\n",
    "            prediction_plot = gr.Image(label=\"Prédictions futures\")\n",
    "            insights_output = gr.Textbox(label=\"Insights & Recommandations\", lines=15)\n",
    "            run_btn.click(\n",
    "                fn=run_analysis,\n",
    "                inputs=[df_json, top_n, prediction_years],\n",
    "                outputs=[analysis_status, lang_dist_plot, trend_plot, prediction_plot, insights_output]\n",
    "            )\n",
    "        \n",
    "        with gr.Tab(\"Monitoring & Évaluation\"):\n",
    "            with gr.Row():\n",
    "                model_selector = gr.Dropdown(\n",
    "                    choices=[\"language_popularity_model\", \"prophet_model\"], \n",
    "                    label=\"Sélectionner un modèle\"\n",
    "                )\n",
    "                eval_threshold = gr.Slider(\n",
    "                    minimum=0.1, maximum=0.9, value=0.5, step=0.1, \n",
    "                    label=\"Seuil pour le réentraînement (R²)\"\n",
    "                )\n",
    "            eval_btn = gr.Button(\"Évaluer et réentraîner si nécessaire\")\n",
    "            eval_status = gr.Textbox(label=\"Statut de l'évaluation\")\n",
    "            metrics_plot = gr.Plot(label=\"Évolution des métriques\")\n",
    "            drift_plot = gr.Plot(label=\"Détection de drift\")\n",
    "            eval_btn.click(\n",
    "                fn=run_evaluation,\n",
    "                inputs=[model_selector, eval_threshold, df_json],\n",
    "                outputs=[eval_status, metrics_plot, drift_plot]\n",
    "            )\n",
    "            \n",
    "            with gr.Tab(\"Apprentissage en temps réel\"):\n",
    "                start_stream_btn = gr.Button(\"Démarrer l'apprentissage en streaming\")\n",
    "                stream_status = gr.Textbox(label=\"Statut du streaming\")\n",
    "                stream_metrics = gr.Plot(label=\"Métriques en temps réel\")\n",
    "                start_stream_btn.click(\n",
    "                    fn=start_streaming,\n",
    "                    outputs=[stream_status, stream_metrics]\n",
    "                )\n",
    "    return app\n",
    "\n",
    "# Fonction principale\n",
    "\n",
    "def main():\n",
    "    setup_mlflow_tracking()\n",
    "    import threading\n",
    "    prediction_thread = threading.Thread(target=start_prediction_service)\n",
    "    prediction_thread.daemon = True\n",
    "    prediction_thread.start()\n",
    "    app_interface = create_interface()\n",
    "    app_interface.launch(share=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cb1229-ae94-4bd5-9241-fdcc77403292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
